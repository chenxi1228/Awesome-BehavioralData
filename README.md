# Awesome-BehaviorData [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

## Tabular Data
### Papers
| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **Tree-based Methods** | | | |
| **XGBoost** | [Xgboost: A scalable tree boosting system](http://dl.acm.org/ft_gateway.cfm?id=2939785&type=pdf) `[PDF]` | Tree | 2016 |
| **LightGBM** | [Lightgbm: A highly efficient gradient boosting decision tree](https://scholar.google.com/scholar?q=Lightgbm%3A%20A%20highly%20efficient%20gradient%20boosting%20decision%20tree) üîç | Tree | 2017 |
| **CatBoost** | [Catboost: unbiased boosting with categorical features](https://scholar.google.com/scholar?q=Catboost%3A%20unbiased%20boosting%20with%20categorical%20features) üîç | Tree | 2018 |
| **Deep Learning-based Methods** | | | |
| **Wide&Deep** | [Wide & deep learning for recommender systems](http://dl.acm.org/ft_gateway.cfm?id=2988454&type=pdf) `[PDF]` | GLM+MLP | 2016 |
| **DeepFM** | [Deepfm: a factorization-machine based neural network for ctr prediction](https://www.ijcai.org/proceedings/2017/0239.pdf) `[PDF]` | FM+MLP | 2017 |
| **xDeepFM** | [xdeepfm: Combining explicit and implicit feature interactions for recommender systems](https://arxiv.org/pdf/1803.05170) `[PDF]` | FM+MLP+CIN | 2018 |
| **TabNN** | [Tabnn: A universal neural network solution for tabular data](https://scholar.google.com/scholar?q=Tabnn%3A%20A%20universal%20neural%20network%20solution%20for%20tabular%20data) üîç | GBDT+MLP | 2018 |
| **RLN** | [Regularization learning networks: deep learning for tabular datasets](https://scholar.google.com/scholar?q=Regularization%20learning%20networks%3A%20deep%20learning%20for%20tabular%20datasets) üîç | MLP | 2018 |
| **NODE** | [Neural oblivious decision ensembles for deep learning on tabular data,](https://scholar.google.com/scholar?q=Neural%20oblivious%20decision%20ensembles%20for%20deep%20learning%20on%20tabular%20data%2C) üîç | NODE | 2019 |
| **SuperTML** | [Supertml: Two-dimensional word embedding for the precognition on structured tabular data](https://scholar.google.com/scholar?q=Supertml%3A%20Two-dimensional%20word%20embedding%20for%20the%20precognition%20on%20structured%20tabular%20data) üîç | CNN | 2019 |
| **TabNet** | [Tabnet: Attentive interpretable tabular learning,](https://scholar.google.com/scholar?q=Tabnet%3A%20Attentive%20interpretable%20tabular%20learning%2C) üîç | TabNet | 2019 |
| **DeepGBM** | [Deepgbm: A deep learning framework distilled by gbt for online prediction tasks](https://scholar.google.com/scholar?q=Deepgbm%3A%20A%20deep%20learning%20framework%20distilled%20by%20gbt%20for%20online%20prediction%20tasks) üîç | DeepGBM | 2019 |
| **NON** | [Network on network for tabular data classification in real-world applications](https://scholar.google.com/scholar?q=Network%20on%20network%20for%20tabular%20data%20classification%20in%20real-world%20applications) üîç | NON | 2020 |
| **DNF-Net** | [Dnf-net: A neural architecture for tabular data,](https://arxiv.org/abs/2006.06465) `[ArXiv]` | DNF-Net | 2020 |
| **VIME** | [Vime: Extending the success of self-and semi-supervised learning to tabular domain](https://scholar.google.com/scholar?q=Vime%3A%20Extending%20the%20success%20of%20self-and%20semi-supervised%20learning%20to%20tabular%20domain) üîç | VIME | 2020 |
| **TabTransformer** | [Tabransformer: Tabular data modeling using contextual embeddings](https://arxiv.org/abs/2012.06678) `[ArXiv]` | Transformer | 2020 |
| **ARM-Net** | [Arm-net: Adaptive relation modeling network for structured data](https://scholar.google.com/scholar?q=Arm-net%3A%20Adaptive%20relation%20modeling%20network%20for%20structured%20data) üîç | ARM-Net | 2021 |
| **NPT** | [Self-attention between datapoints: Going beyond individual input-output pairs in deep learning](https://scholar.google.com/scholar?q=Self-attention%20between%20datapoints%3A%20Going%20beyond%20individual%20input-output%20pairs%20in%20deep%20learning) üîç | Transformer | 2021 |
| **Regularized DNNs** | [Well-tuned simple nets excel on tabular datasets](https://arxiv.org/abs/2106.11189) `[ArXiv]` | MLP | 2021 |
| **Boost-GNN** | [Boost then convolve: Gradient boosting meets graph neural networks,](https://arxiv.org/abs/2101.08543) `[ArXiv]` | GBDT+GNN | 2021 |
| **DNN2LR** | [Dnn2lr: Interpretation-inspired feature crossing for real-world tabular data,](https://arxiv.org/abs/2008.09775) `[ArXiv]` | DNN2LR | 2021 |
| **IGTD** | [Converting tabular data into images for deep learning with convolutional neural networks](https://scholar.google.com/scholar?q=Converting%20tabular%20data%20into%20images%20for%20deep%20learning%20with%20convolutional%20neural%20networks) üîç | IGTD+CNN | 2021 |
| **FT-Transformer** | [Revisiting deep learning models for tabular data,](https://arxiv.org/abs/2106.11959) `[ArXiv]` | Transformer | 2021 |
| **SAINT** | [Saint: Improved neural networks for tabular data via row attention and contrastive pre-training,](https://scholar.google.com/scholar?q=Saint%3A%20Improved%20neural%20networks%20for%20tabular%20data%20via%20row%20attention%20and%20contrastive%20pre-training%2C) üîç | SAINT | 2021 |
| **SCARF** | [Scarf: Self-supervised contrastive learning using random feature corruption](https://scholar.google.com/scholar?q=Scarf%3A%20Self-supervised%20contrastive%20learning%20using%20random%20feature%20corruption) üîç | MLP | 2021 |
| **GANDALF** | [Gandalf: gated adaptive network for deep automated learning of features](https://arxiv.org/abs/2207.08548) `[ArXiv]` | GFLU | 2022 |
| **TabDDPM** | [Tabddpm: Modelling tabular data with diffusion models](https://arxiv.org/abs/2209.15421) `[ArXiv]` | Diffusion Model | 2022 |
| **Ptab** | [Ptab: Using the pre-trained language model for modeling tabular data,](http://arxiv.org/pdf/2209.08060) `[PDF]` | BERT | 2022 |
| **Trompt** | [Prompt: Towards a better deep neural network for tabular data](https://scholar.google.com/scholar?q=Prompt%3A%20Towards%20a%20better%20deep%20neural%20network%20for%20tabular%20data) üîç | MLP | 2023 |
| **HYTREL** | [Hytrel: Hypergraph-enhanced tabular data representation learning](https://scholar.google.com/scholar?q=Hytrel%3A%20Hypergraph-enhanced%20tabular%20data%20representation%20learning) üîç | HYTREL | 2023 |
| **ReConTab** | [Recontab: Regularized contrastive representation learning for tabular data](https://scholar.google.com/scholar?q=Recontab%3A%20Regularized%20contrastive%20representation%20learning%20for%20tabular%20data) üîç | Transformer | 2023 |
| **XTab** | [Xtab: Cross-table pretraining for tabular transformers](http://arxiv.org/pdf/2305.06090) `[PDF]` | Transformer | 2023 |
| **MambaTab** | [Mambatab: A plug-and-play model for learning tabular data,](https://scholar.google.com/scholar?q=Mambatab%3A%20A%20plug-and-play%20model%20for%20learning%20tabular%20data%2C) üîç | Mamba | 2024 |
| **BiSHop** | [Bishop: Bi-directional cellular learning for tabular data with generalized sparse modern hopfield model](https://scholar.google.com/scholar?q=Bishop%3A%20Bi-directional%20cellular%20learning%20for%20tabular%20data%20with%20generalized%20sparse%20modern%20hopfield%20model) üîç | BiSHop | 2024 |
| **LF-transformer** | [Lf-transformer: Latent factorizer transformer for tabular learning](https://scholar.google.com/scholar?q=Lf-transformer%3A%20Latent%20factorizer%20transformer%20for%20tabular%20learning) üîç | Transformer | 2024 |
| **TabR** | [Tabr: Tabular deep learning meets nearest neighbors](https://scholar.google.com/scholar?q=Tabr%3A%20Tabular%20deep%20learning%20meets%20nearest%20neighbors) üîç | TabR | 2024 |
| **TP-BERTa** | [Making pre-trained language models great on tabular prediction](https://scholar.google.com/scholar?q=Making%20pre-trained%20language%20models%20great%20on%20tabular%20prediction) üîç | BERT | 2024 |
| **CARTE** | [Carte: pretraining and transfer for tabular learning](https://scholar.google.com/scholar?q=Carte%3A%20pretraining%20and%20transfer%20for%20tabular%20learning) üîç | Transformer | 2024 |
| **SwitchTab** | [Switchtab: Switched autoencoders are effective tabular learners](https://scholar.google.com/scholar?q=Switchtab%3A%20Switched%20autoencoders%20are%20effective%20tabular%20learners) üîç | Transformer | 2024 |
| **LLM-driven Methods** | | | |
| **TAPAS** | [Tapas: Weakly supervised table parsing via pre-training,](https://www.aclweb.org/anthology/2020.acl-main.398.pdf) `[PDF]` | Bert | 2020 |
| **TAPEX** | [Tapex: Table pre-training via learning a neural sql executor](https://scholar.google.com/scholar?q=Tapex%3A%20Table%20pre-training%20via%20learning%20a%20neural%20sql%20executor) üîç | Transformer | 2022 |
| **TabLLM** | [Tabllm: Few-shot classification of tabular data with large language models](http://arxiv.org/pdf/2210.10723) `[PDF]` | Transformer | 2022 |
| **cTBLS** | [ctbls: Augmenting large language models with conversational tables](https://aclanthology.org/2023.nlp4convai-1.6.pdf) `[PDF]` | Transformer | 2023 |

### Benchmarks


| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **OpenGL-CC18** | [OpenGL-CC18](#) `[None]` | https://www.openml.org/search?type=benchmark&sort=tasks INCLUDED&study_type=task&id=99 | 2017 |
| **WellTunedSimpleNets** | [WellTunedSimpleNets](#) `[None]` | https://github.com/machinelearningnuremberg/WellTunedSimpleNets | 2021 |
| **TabularBench** | [TabularBench](#) `[None]` | https://github.com/LeoGrin/tabular-benchmark | 2022 |
| **TabZilla** | [TabZilla](#) `[None]` | https://github.com/naszilla/tabzilla | 2023 |
| **OpenTabs** | [OpenTabs](#) `[None]` | https://github.com/Chao-Ye/CM2 | 2024 |
| **TALENT** | [TALENT](#) `[None]` | https://github.com/LAMDA-Tabular/TALENT | 2024 |

### Dataset Resources


| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **California Housing (CA)** | [California Housing (CA)](#) `[None]` | 0 | Regression |
| **Adult (AD)** | [Adult (AD)](#) `[None]` | 8 | Classification |
| **Helena (HE)** | [Helena (HE)](#) `[None]` | 0 | Classification |
| **Jannis (JA)** | [Jannis (JA)](#) `[None]` | 0 | Classification |
| **Higgs (HI)** | [Higgs (HI)](#) `[None]` | 0 | Classification |
| **ALOI(AL)** | [ALOI(AL)](#) `[None]` | 0 | Classification |
| **Epsilon (EP)** | [Epsilon (EP)](#) `[None]` | 0 | Classification |
| **Year (YE)** | [Year (YE)](#) `[None]` | 0 | Regression |
| **Covertype(CO)** | [Covertype(CO)](#) `[None]` | 0 | classification |
| **Bank(BK)** | [Bank(BK)](#) `[None]` | 9 | classification |
| **Blastchar (BC)** | [Blastchar (BC)](#) `[None]` | 17 | classification |
| **Shoppers (SH)** | [Shoppers (SH)](#) `[None]` | 14 | classification |
| **Volkert (VO)** | [Volkert (VO)](#) `[None]` | 1 | classification |
| **Income (IC)** | [Income (IC)](#) `[None]` | 8 | Classification |
| **Yahoo (YA)** | [Yahoo (YA)](#) `[None]` | 0 | Regression |
| **Microsoft (MI)** | [Microsoft (MI)](#) `[None]` | 0 | Regression |

## Event Sequence

### Papers
| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **Symbolic Modeling Methods** | | | |
| **FPMC** | [Factorizing personalized markov chains for next-basket recommendation,](http://www.ismll.uni-hildesheim.de/pub/pdfs/RendleFreudenthaler2010-FPMC.pdf) `[PDF]` | Markov Chain | 2010 |
| **PSPM** | [Effective next-items recommendation via personalized sequential pattern mining](https://scholar.google.com/scholar?q=Effective%20next-items%20recommendation%20via%20personalized%20sequential%20pattern%20mining) üîç | Sequential Pattern Mining | 2012 |
| **PRME** | [Personalized ranking metric embedding for next new poi recommendation,](https://scholar.google.com/scholar?q=Personalized%20ranking%20metric%20embedding%20for%20next%20new%20poi%20recommendation%2C) üîç | Markov Chain | 2015 |
| **Deep Learning-based Methods** | | | |
| **GRU4Rec** | [Session-based recommendations with recurrent neural networks](https://scholar.google.com/scholar?q=Session-based%20recommendations%20with%20recurrent%20neural%20networks) üîç | GRU | 2015 |
| **RMTPP** | [Recurrent marked temporal point processes: Embedding event history to vector](https://doi.org/10.1145/2939672.2939875) `[DOI]` | RNN | 2016 |
| **NHP** | [The neural hawkes process: A neurally selfmodulating multivariate point process,](https://scholar.google.com/scholar?q=The%20neural%20hawkes%20process%3A%20A%20neurally%20selfmodulating%20multivariate%20point%20process%2C) üîç | LSTM | 2017 |
| **Event2Vec** | [Event2vec: Learning representations of events on temporal sequences,](https://doi.org/10.1007/978-3-319-63564-4_3) `[DOI]` | Transformer | 2017 |
| **IRGAN** | [Irgan: A minimax game for unifying generative and discriminative information retrieval models](https://eprints.bbk.ac.uk/id/eprint/18782/6/18782.pdf) `[PDF]` | GAN | 2017 |
| **HRNN** | [Personalizing session-based recommendations with hierarchical recurrent neural networks](https://arxiv.org/pdf/1706.04148) `[PDF]` | RNN | 2017 |
| **Caser** | [Personalized top-n sequential recommendation via convolutional sequence embedding,](https://arxiv.org/pdf/1809.07426) `[PDF]` | CNN | 2018 |
| **AttRec** | [Next item recommendation with self-attention](https://arxiv.org/abs/1808.06414) `[ArXiv]` | Transformer | 2018 |
| **MANN** | [Sequential recommendation with user memory networks](https://scholar.google.com/scholar?q=Sequential%20recommendation%20with%20user%20memory%20networks) üîç | Memory Network | 2018 |
| **RecGAN** | [Recgan: recurrent generative adversarial networks for recommendation systems](https://scholar.google.com/scholar?q=Recgan%3A%20recurrent%20generative%20adversarial%20networks%20for%20recommendation%20systems) üîç | GAN+RNN | 2018 |
| **BERT4Rec** | [Bert4rec: Sequential recommendation with bidirectional encoder representations from transformer](https://arxiv.org/abs/1904.06690) `[ArXiv]` | BERT | 2019 |
| **DTCDR** | [Dtcdr: A framework for dual-target cross-domain recommendation](https://scholar.google.com/scholar?q=Dtcdr%3A%20A%20framework%20for%20dual-target%20cross-domain%20recommendation) üîç | MLP | 2019 |
| **FDSA** | [Feature-level deeper self-attention network for sequential recommendation.](https://www.ijcai.org/proceedings/2019/0600.pdf) `[PDF]` | Transformer | 2019 |
| **NextItNet** | [A simple convolutional generative network for next item recommendation,](https://scholar.google.com/scholar?q=A%20simple%20convolutional%20generative%20network%20for%20next%20item%20recommendation%2C) üîç | CNN | 2019 |
| **SAHP** | [Self-attentive hawkes process](https://scholar.google.com/scholar?q=Self-attentive%20hawkes%20process) üîç | Transformer | 2020 |
| **THP** | [Transformer hawkes process,](https://arxiv.org/abs/2002.09291) `[ArXiv]` | Transformer | 2020 |
| **BEHRT** | [Behrt: transformer for electronic health records](https://www.nature.com/articles/s41598-020-62922-y.pdf) `[PDF]` | BERT | 2020 |
| **TiSASRec** | [Time interval aware self-attention for sequential recommendation](https://dl.acm.org/doi/pdf/10.1145/3336191.3371786) `[PDF]` | Transformer | 2020 |
| **RAPT** | [Rapt: Pre-training of time-aware transformer for learning robust healthcare representation,](https://doi.org/10.1145/3447548.3467069) `[DOI]` | Transformer | 2021 |
| **CoSeRec** | [Contrastive self-supervised sequential recommendation with robust augmentation](https://scholar.google.com/scholar?q=Contrastive%20self-supervised%20sequential%20recommendation%20with%20robust%20augmentation) üîç | GAN+CL | 2021 |
| **ASReP** | [Augmenting sequential recommendation with pseudo-prior items via reversely pre-training transformer](https://scholar.google.com/scholar?q=Augmenting%20sequential%20recommendation%20with%20pseudo-prior%20items%20via%20reversely%20pre-training%20transformer) üîç | Transformer | 2021 |
| **UniSRec** | [Towards universal sequence representation learning for recommender systems](https://arxiv.org/pdf/2206.05941) `[PDF]` | BERT+Transformer | 2022 |
| **RecGURU** | [Recguru: Adversarial learning of generalized user representations for cross-domain recommendation](https://scholar.google.com/scholar?q=Recguru%3A%20Adversarial%20learning%20of%20generalized%20user%20representations%20for%20cross-domain%20recommendation) üîç | Transformer | 2022 |
| **promptTPP** | [Prompt-augmented temporal point process for streaming event sequence,](https://arxiv.org/pdf/2310.04993) `[PDF]` | Transformer+ Prompts | 2023 |
| **Meta TPP** | [Meta temporal point processes,](https://scholar.google.com/scholar?q=Meta%20temporal%20point%20processes%2C) üîç | Transformer | 2023 |
| **BERT4ETH** | [Bert4eth: A pretrained transformer for ethereum fraud detection,](https://scholar.google.com/scholar?q=Bert4eth%3A%20A%20pretrained%20transformer%20for%20ethereum%20fraud%20detection%2C) üîç | BERT | 2023 |
| **PrimeNet** | [Primenet: Pre-training for irregular multivariate time series](https://scholar.google.com/scholar?q=Primenet%3A%20Pre-training%20for%20irregular%20multivariate%20time%20series) üîç | Transformer | 2023 |
| **ECGAN-Rec** | [Enhancing sequential recommendation with contrastive generative adversarial network,](https://scholar.google.com/scholar?q=Enhancing%20sequential%20recommendation%20with%20contrastive%20generative%20adversarial%20network%2C) üîç | GAN | 2023 |
| **Player2Vec** | [player2vec: A language modeling approach to understand player behavior in games](https://arxiv.org/abs/2404.04234) `[ArXiv]` | BERT | 2024 |
| **Residual TPP** | [Residual TPP: A unified lightweight approach for event stream data analysis,](https://scholar.google.com/scholar?q=Residual%20TPP%3A%20A%20unified%20lightweight%20approach%20for%20event%20stream%20data%20analysis%2C) üîç | Hawkes + Neural TPP | 2025 |
| **IOCLRc** | [Intent oriented contrastive learning for sequential recommendation,](https://scholar.google.com/scholar?q=Intent%20oriented%20contrastive%20learning%20for%20sequential%20recommendation%2C) üîç | Transformer+CL | 2025 |
| **HORAE** | [Horae: Temporal multi-interest pre-training for sequential recommendation](https://scholar.google.com/scholar?q=Horae%3A%20Temporal%20multi-interest%20pre-training%20for%20sequential%20recommendation) üîç | Transformer | 2025 |

### Benchmarks


| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **GRU** | [GRU](#) `[None]` | https://github.com/clientGe/Sequential_Recommendation_Tensorflow | 2015 |
| **BERT** | [BERT](#) `[None]` | https://github.com/google-research/bert | 2017 |
| **CPC** | [CPC](#) `[None]` | https://github.com/davidtellz/contrastive-predictive-coding | 2018 |
| **Transformer** | [Transformer](#) `[None]` | https://github.com/jadore801120/attention-is-all-you-need-pytorch | 2017 |
| **PrimeNet** | [PrimeNet](#) `[None]` | https://github.com/ranakroychowdhury/PrimeNet | 2023 |
| **RMTPP** | [RMTPP](#) `[None]` | https://github.com/ivan-chai/hotpp-benchmark | 2016 |



### Dataset Resources

| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **Amazon Product Reviews 2023** | [Amazon Product Reviews 2023](#) `[None]` | 48.19M | E-commerce |
| **Amazon Q&A** | [Amazon Q&A](#) `[None]` | 191K | E-commerce |
| **ModCloth Marketing Bias** | [ModCloth Marketing Bias](#) `[None]` | 1.02K | E-commerce |
| **Google Local Reviews 2021** | [Google Local Reviews 2021](#) `[None]` | 4.96M | Local Services |
| **Google Restaurants** | [Google Restaurants](#) `[None]` | 65K | Local Services |
| **Twitch** | [Twitch](#) `[None]` | 465K | Media Content |
| **Food.com Recipe & Review** | [Food.com Recipe & Review](#) `[None]` | 231.64K | Media Content |
| **EndoMondo Fitness Tracking Data** | [EndoMondo Fitness Tracking Data](#) `[None]` | - | Healthcare |
| **Behance Community Art Data** | [Behance Community Art Data](#) `[None]` | 178.79K | Art |
| **Taobao UserBehavior** | [Taobao UserBehavior](#) `[None]` | 4.16M | E-commerce |
| **MovieLens 32M** | [MovieLens 32M](#) `[None]` | 87.59K | Media Content |
| **Steam Video Game and Bundle Data** | [Steam Video Game and Bundle Data](#) `[None]` | 15.47K Items, 615 Bundles | Gaming |


## Dynamic Graph

### Papers
#### Discrete-Time Dynamic Graph (DTDG)
| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **Static Embedding + Temporal Alignment Methods** | | | |
| **Chakrabarti et al. , Chi et al. ,Kim & Han , Gupta et al. ,Yao et al. , Zhou et al.** | [Evolutionary clustering,](https://doi.org/10.1109/TEVC.2022.3184988) `[DOI]` | Smoothness regularization or alignment | 2006-2018 |
| **Hisano** | [Semi-supervised graph embedding approach to dynamic link prediction](https://scholar.google.com/scholar?q=Semi-supervised%20graph%20embedding%20approach%20to%20dynamic%20link%20prediction) üîç | Time window aggregation | 2018 |
| **Sharan & Neville** | [Temporal-relational classifiers for prediction in evolving domains,](https://doi.org/10.1109/ICDM.2008.125) `[DOI]` | Time-weighted adjacency matrices | 2008 |
| **Ibrahim et al.** | [Link prediction in dynamic social networks by integrating different types of information,](https://scholar.google.com/scholar?q=Link%20prediction%20in%20dynamic%20social%20networks%20by%20integrating%20different%20types%20of%20information%2C) üîç | Exponential decay | 2015 |
| **Ahmed et al.** | [Sampling-based algorithm for link prediction in temporal networks,](https://scholar.google.com/scholar?q=Sampling-based%20algorithm%20for%20link%20prediction%20in%20temporal%20networks%2C) üîç | Temporal sampling strategies | 2016 |
| **Singer et al.** | [Node embedding over temporal graphs](https://www.ijcai.org/proceedings/2019/0640.pdf) `[PDF]` | Init. from previous step + fine-tuning | 2019 |
| **DynGEM** | [Dyngem: Deep embedding method for dynamic graphs](https://arxiv.org/abs/1805.11273) `[ArXiv]` | Regularization across snapshots | 2018 |
| **DynamicTriad** | [Dynamic network embedding by modeling triadic closure process](https://ojs.aaai.org/index.php/AAAI/article/download/11257/11116) `[PDF]` | Temporal smoothness | 2018 |
| **GNN+RNN-based Methods** | | | |
| **GCRN** | [Structured sequence modeling with graph convolutional recurrent networks](https://arxiv.org/abs/1612.07659) `[ArXiv]` | LSTM | 2018 |
| **Narayan & Roe** | [Learning graph dynamics using deep neural networks,](https://doi.org/10.1016/j.ifacol.2018.03.074) `[PDF]` | LSTM | 2018 |
| **TGCN** | [T-gcn: A temporal graph convolutional network for traffic prediction,](https://arxiv.org/pdf/1811.05320) `[PDF]` | GRU | 2019 |
| **TNA** | [Temporal neighbourhood aggregation: Predicting future links in temporal graphs via recurrent variational graph convolutions,](https://scholar.google.com/scholar?q=Temporal%20neighbourhood%20aggregation%3A%20Predicting%20future%20links%20in%20temporal%20graphs%20via%20recurrent%20variational%20graph%20convolutions%2C) üîç | GRU | 2019 |
| **VGRNN** | [Variational graph recurrent neural networks](https://arxiv.org/abs/1908.09710) `[ArXiv]` | LSTM | 2019 |
| **LRGCN** | [Predicting path failure in time-evolving graphs](https://arxiv.org/pdf/1905.03994) `[PDF]` | LSTM | 2019 |
| **E-LSTM-D** | [E-lstm-d: A deep learning framework for dynamic network link prediction](https://scholar.google.com/scholar?q=E-lstm-d%3A%20A%20deep%20learning%20framework%20for%20dynamic%20network%20link%20prediction) üîç | LSTM | 2019 |
| **EvolveGCN** | [Evolvegn: Evolving graph convolutional networks for dynamic graphs](https://ojs.aaai.org/index.php/AAAI/article/download/5984/5840) `[PDF]` | GRU | 2020 |
| **dygraph2vec** | [dyngraph2vec: Capturing network dynamics using dynamic graph representation learning](https://arxiv.org/pdf/1809.02657) `[PDF]` | LSTM/GRU | 2020 |
| **TeMP** | [Temp: Temporal message passing for temporal knowledge graph completion,](https://www.aclweb.org/anthology/2020.emnlp-main.462.pdf) `[PDF]` | GRU or Attention | 2020 |
| **WD-GCN/CD-GCN** | [Dynamic graph convolutional networks](https://ieeexplore.ieee.org/ielx7/4609443/4609444/10380452.pdf) `[PDF]` | Modified LSTM | 2020 |
| **HDGNN** | [A heterogeneous dynamical graph neural networks approach to quantify scientific impact,](https://arxiv.org/abs/2003.12042) `[ArXiv]` | Bi-RNN | 2020 |
| **HTGN** | [Discretetime temporal network embedding via implicit hierarchical learning in hyperbolic space](https://arxiv.org/pdf/2107.03767) `[PDF]` | Hyperbolic GRU | 2021 |
| **GC-LSTM** | [Gc-lstm: Graph convolution embedded LSTM for dynamic network link prediction](https://arxiv.org/abs/1812.04206) `[ArXiv]` | LSTM | 2022 |
| **ROLAND** | [Roland: graph learning framework for dynamic graphs,](https://scholar.google.com/scholar?q=Roland%3A%20graph%20learning%20framework%20for%20dynamic%20graphs%2C) üîç | Adaptive RNN | 2022 |
| **RPC** | [Learn from relational correlations and periodic events for temporal knowledge graph reasoning,](https://scholar.google.com/scholar?q=Learn%20from%20relational%20correlations%20and%20periodic%20events%20for%20temporal%20knowledge%20graph%20reasoning%2C) üîç | GRU | 2023 |
| **SEIGN** | [Seign: A simple and efficient graph neural network for large dynamic graphs](https://doi.org/10.1109/ICDE55515.2023.00218) `[DOI]` | GRU parameter adjustments | 2023 |
| **RETIA** | [Retia: relation-entity twin-interact aggregation for temporal knowledge graph extrapolation](https://scholar.google.com/scholar?q=Retia%3A%20relation-entity%20twin-interact%20aggregation%20for%20temporal%20knowledge%20graph%20extrapolation) üîç | GRU + LSTM | 2023 |
| **MegaCRN** | [Spatio-temporal meta-graph learning for traffic forecasting](http://arxiv.org/pdf/2211.14701) `[PDF]` | Custom GRU | 2023 |
| **DEFT** | [Learnable spectral wavelets on dynamic graphs to capture global interactions](https://arxiv.org/pdf/2211.11979) `[PDF]` | RNN-based parameter evolution +Wavelet | 2023 |
| **STGNPP** | [Spatio-temporal graph neural point process for traffic congestion event prediction](https://ojs.aaai.org/index.php/AAAI/article/download/26669/26441) `[PDF]` | Continuous GRU | 2023 |
| **WinGNN** | [Wingnn: dynamic graph neural networks with random gradient aggregation window](https://scholar.google.com/scholar?q=Wingnn%3A%20dynamic%20graph%20neural%20networks%20with%20random%20gradient%20aggregation%20window) üîç | Sliding window | 2023 |
| **SpikeNet** | [Scaling up dynamic graph representation learning via spiking neural networks](http://arxiv.org/pdf/2208.10364) `[PDF]` | SSN | 2023 |
| **TTGCN** | [K-truss based temporal graph convolutional network for dynamic graphs,](https://scholar.google.com/scholar?q=K-truss%20based%20temporal%20graph%20convolutional%20network%20for%20dynamic%20graphs%2C) üîç | GRU | 2024 |
| **Attention-based Methods** | | | |
| **DySAT** | [Dysat: Deep neural representation learning on dynamic graphs via self-attention networks](https://scholar.google.com/scholar?q=Dysat%3A%20Deep%20neural%20representation%20learning%20on%20dynamic%20graphs%20via%20self-attention%20networks) üîç | Graph attention | 2020 |
| **TEDIC** | [Tedic: Neural modeling of behavioral patterns in dynamic social interaction networks,](https://doi.org/10.1145/3442381.3450096) `[DOI]` | Temporal Convolutional Network | 2021 |
| **DyHATR** | [Modeling dynamic heterogeneous network for link prediction using hierarchical attention with temporal mn](https://scholar.google.com/scholar?q=Modeling%20dynamic%20heterogeneous%20network%20for%20link%20prediction%20using%20hierarchical%20attention%20with%20temporal%20mn) üîç | Temporal attentive RNN | 2021 |
| **DREAM** | [Dream: Adaptive reinforcement learning based on attention mechanism for temporal knowledge graph reasoning,](https://arxiv.org/pdf/2304.03984) `[PDF]` | Attention + Reinforcement learning | 2023 |
| **STGNP** | [Graph neural processes for spatio-temporal extrapolation](https://dl.acm.org/doi/pdf/10.1145/3580305.3599372) `[PDF]` | Cross-set Graph Convolution | 2023 |
| **DTFormer** | [Dtformer: A transformer-based method for discrete-time dynamic graph representation learning](https://scholar.google.com/scholar?q=Dtformer%3A%20A%20transformer-based%20method%20for%20discrete-time%20dynamic%20graph%20representation%20learning) üîç | Transformer | 2024 |

#### Continuous-Time Dynamic Graph (CTDG)

| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **RNN-based Methods** | | | |
| **DeepCoevolve** | [Deep coevolutionary network: Embedding user and item features for recommendation,](https://scholar.google.com/scholar?q=Deep%20coevolutionary%20network%3A%20Embedding%20user%20and%20item%20features%20for%20recommendation%2C) üîç | RNN | 2018 |
| **JODIE** | [Predicting dynamic embedding trajectory in temporal interaction networks,](https://europepmc.org/articles/pmc6752886?pdf=render) `[PDF]` | RNN + Projection | 2020 |
| **Know-Evolve** | [Know-evolve: Deep temporal reasoning for dynamic knowledge graphs,](https://scholar.google.com/scholar?q=Know-evolve%3A%20Deep%20temporal%20reasoning%20for%20dynamic%20knowledge%20graphs%2C) üîç | RNN | 2017 |
| **RE-Net** | [Recurrent event network: Autoregressive structure inferenceover temporal knowledge graphs](https://scholar.google.com/scholar?q=Recurrent%20event%20network%3A%20Autoregressive%20structure%20inferenceover%20temporal%20knowledge%20graphs) üîç | RNN | 2020 |
| **HierTCN** | [Hierarchical temporal convolutional networks for dynamic recommender systems](https://scholar.google.com/scholar?q=Hierarchical%20temporal%20convolutional%20networks%20for%20dynamic%20recommender%20systems) üîç | GRU + TCN | 2019 |
| **DynGESN** | [Dynamic graph echo state networks](https://scholar.google.com/scholar?q=Dynamic%20graph%20echo%20state%20networks) üîç | Echo State Network | 2021 |
| **DyGNN** | [Streaming graph neural networks](https://arxiv.org/pdf/2009.10951) `[PDF]` | LSTM | 2020 |
| **AER-AD** | [Anonymous edge representation for inductive anomaly detection in dynamic bipartite graph](https://doi.org/10.14778/3579075.3579088) `[DOI]` | GRU | 2023 |
| **RTRGN** | [Recurrent temporal revision graph networks](https://arxiv.org/pdf/2309.12694) `[PDF]` | RNN | 2023 |
| **TGN** | [Temporal graph networks for deep learning on dynamic graphs,](https://arxiv.org/abs/2006.10637) `[ArXiv]` | RNN + Memory | 2020 |
| **NAT** | [Neighborhood-aware scalable temporal network representation learning](https://arxiv.org/pdf/2209.01084) `[PDF]` | RNN | 2022 |
| **GDCF** | [Generic and dynamic graph representation learning for crowd flow modeling](https://scholar.google.com/scholar?q=Generic%20and%20dynamic%20graph%20representation%20learning%20for%20crowd%20flow%20modeling) üîç | RNN + Memory | 2023 |
| **CDGP** | [Dynamic heterogeneous graph attention neural architecture search](https://scholar.google.com/scholar?q=Dynamic%20heterogeneous%20graph%20attention%20neural%20architecture%20search) üîç | Time-aware aggregation | 2023 |
| **TIGER** | [Tiger: Temporal interaction graph embedding with restarts,](https://scholar.google.com/scholar?q=Tiger%3A%20Temporal%20interaction%20graph%20embedding%20with%20restarts%2C) üîç | RNN + Dual Memory | 2023 |
| **RDGL** | [Rdgsl: Dynamic graph representation learning with structure learning](https://arxiv.org/pdf/2309.02025) `[PDF]` | RNN + Memory | 2023 |
| **PRES** | [Pres: Toward scalable memory-based dynamic graph neural networks,](https://arxiv.org/abs/2402.04284) `[ArXiv]` | GMM-guided memory correction | 2024 |
| **Ada-DyGNN** | [Robust knowledge adaptation for dynamic graph neural networks,](https://scholar.google.com/scholar?q=Robust%20knowledge%20adaptation%20for%20dynamic%20graph%20neural%20networks%2C) üîç | Time-based Policy | 2024 |
| **SEAN** | [Towards adaptive neighborhood for advancing temporal interaction graph modeling](https://arxiv.org/pdf/2406.11891) `[PDF]` | RNN + Temporal-aware aggregation | 2024 |
| **MemMap** | [Memmap: An adaptive and latent memory structure for dynamic graph learning](https://doi.org/10.1145/3637528.3672060) `[DOI]` | Systematic memory routing | 2024 |
| **MSPipe** | [Mpipe: Efficient temporal gnn training via staleness-aware pipeline](https://scholar.google.com/scholar?q=Mpipe%3A%20Efficient%20temporal%20gnn%20training%20via%20staleness-aware%20pipeline) üîç | Staleness-aware update | 2024 |
| **TPP-based Methods** | | | |
| **HTNE** | [Embedding temporal network via neighborhood formation](https://scholar.google.com/scholar?q=Embedding%20temporal%20network%20via%20neighborhood%20formation) üîç | Hawkes Process | 2018 |
| **M2DNE** | [Temporal network embedding with micro-and macro-dynamics,](https://scholar.google.com/scholar?q=Temporal%20network%20embedding%20with%20micro-and%20macro-dynamics%2C) üîç | Hierarchical TPP | 2019 |
| **GHN** | [The graph hawkes network for reasoning on temporal knowledge graphs,](https://scholar.google.com/scholar?q=The%20graph%20hawkes%20network%20for%20reasoning%20on%20temporal%20knowledge%20graphs%2C) üîç | Hawkes Process | 2019 |
| **DyRep** | [Dyrep: Learning representations over dynamic graphs](https://scholar.google.com/scholar?q=Dyrep%3A%20Learning%20representations%20over%20dynamic%20graphs) üîç | Multi-scale TPP | 2019 |
| **LDG** | [Learning temporal attention in dynamic graphs with bilinear interactions](https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0247936&type=printable) `[PDF]` | Adaptive TPP | 2021 |
| **TREND** | [Trend: Temporal event and node dynamics for graph representation learning,](https://ink.library.smu.edu.sg/context/sis_research/article/8485/viewcontent/TheWebConf22_TREND.pdf) `[PDF]` | Hawkes Process + Transfer function | 2022 |
| **DynShare** | [Time-interval aware share recommendation via bi-directional continuous time dynamic graphs](https://doi.org/10.1145/3539618.3591775) `[DOI]` | Personalized TPP | 2023 |
| **EasyDGL** | [Easydsl: Encode, train and interpret for continuous-time dynamic graph learning](https://scholar.google.com/scholar?q=Easydsl%3A%20Encode%2C%20train%20and%20interpret%20for%20continuous-time%20dynamic%20graph%20learning) üîç | TPP + Correlation masking | 2024 |
| **Random Walk-based Methods** | | | |
| **CTDNE** | [Dynamic network embeddings: From random walks to temporal random walks](https://scholar.google.com/scholar?q=Dynamic%20network%20embeddings%3A%20From%20random%20walks%20to%20temporal%20random%20walks) üîç | Skip-Gram over walks | 2018 |
| **HNIP** | [Temporal network embedding with high-order nonlinear information](https://ojs.aaai.org/index.php/AAAI/article/download/5993/5849) `[PDF]` | Time-decay in walk sequence | 2020 |
| **CAW** | [Inductive representation learning in temporal networks via causal anonymous walks](https://arxiv.org/abs/2101.05974) `[ArXiv]` | Hitting-count encoding | 2021 |
| **NeurTWs** | [Neural temporal walks: Motif-aware representation learning on continuous-time dynamic graphs](https://scholar.google.com/scholar?q=Neural%20temporal%20walks%3A%20Motif-aware%20representation%20learning%20on%20continuous-time%20dynamic%20graphs) üîç | ODE over walk path | 2022 |
| **PINT** | [Provably expressive temporal graph networks](http://arxiv.org/pdf/2209.15059) `[PDF]` | Provable temporal message passing | 2022 |
| **TPNet** | [Improving temporal link prediction via temporal walk matrix projection,](https://scholar.google.com/scholar?q=Improving%20temporal%20link%20prediction%20via%20temporal%20walk%20matrix%20projection%2C) üîç | Temporal relative encoding | 2024 |
| **Attention/Time Encoding-based Methods** | | | |
| **TGAT** | [Inductive representation learning on temporal graphs](https://scholar.google.com/scholar?q=Inductive%20representation%20learning%20on%20temporal%20graphs) üîç | Functional Time Encoding | 2020 |
| **TCL** | [Tcl: Transformer-based dynamic graph modelling via contrastive learning](https://arxiv.org/abs/2105.07944) `[ArXiv]` | Functional Time Encoding | 2021 |
| **OTGNet** | [Towards open temporal graph neural networks,](https://scholar.google.com/scholar?q=Towards%20open%20temporal%20graph%20neural%20networks%2C) üîç | Extended Time Encoding | 2023 |
| **TGRank** | [Expressive and efficient representation learning for ranking links in temporal graphs](https://scholar.google.com/scholar?q=Expressive%20and%20efficient%20representation%20learning%20for%20ranking%20links%20in%20temporal%20graphs) üîç | Enhanced Time Encoding | 2023 |
| **DHGAS** | [Community-based dynamic graph learning for popularity prediction](https://doi.org/10.1145/3580305.3599281) `[DOI]` | Time Encoding | 2023 |
| **SimpleDyG** | [On the feasibility of simple transformer for dynamic graph modeling](https://ink.library.smu.edu.sg/context/sis_research/article/9713/viewcontent/Pure_Transformer_for_Dynamic_Graphs__WWW24_.pdf) `[PDF]` | Time and Position Encoding | 2024 |
| **DyGFormer** | [Towards better dynamic graph learning: New architecture and unified library](https://arxiv.org/pdf/2303.13047) `[PDF]` | Time and Position Encoding | 2024 |
| **APAN** | [Apan: Asynchronous propagation attention network for real-time temporal graph embedding](https://scholar.google.com/scholar?q=Apan%3A%20Asynchronous%20propagation%20attention%20network%20for%20real-time%20temporal%20graph%20embedding) üîç | Time Encoding | 2021 |
| **iLoRE** | [ilore: Dynamic graph representation with instant long-term modeling and re-occurrence preservation](https://scholar.google.com/scholar?q=ilore%3A%20Dynamic%20graph%20representation%20with%20instant%20long-term%20modeling%20and%20re-occurrence%20preservation) üîç | Time Encoding | 2022 |
| **TDGNN** | [Continuous-time link prediction via temporal dependent graph neural network](https://doi.org/10.1145/3366423.3380073) `[DOI]` | Exponential Decay Kernel | 2020 |
| **DGEL** | [Dynamic graph evolution learning for recommendation](https://doi.org/10.1145/3539618.3591674) `[DOI]` | Time-aware Normalization | 2023 |
| **SUPA** | [Instant representation learning for recommendation over large dynamic graphs](http://arxiv.org/pdf/2305.18622) `[PDF]` | Time modeling mechanisms | 2023 |
| **FreeDyG** | [Freedyg: Frequency enhanced continuous-time dynamic graph model for link prediction](https://scholar.google.com/scholar?q=Freedyg%3A%20Frequency%20enhanced%20continuous-time%20dynamic%20graph%20model%20for%20link%20prediction) üîç | Functional Time Encoding | 2024 |
| **CNE-N** | [Co-neighbor encoding schema: A light-cost structure encoding method for dynamic link prediction](https://scholar.google.com/scholar?q=Co-neighbor%20encoding%20schema%3A%20A%20light-cost%20structure%20encoding%20method%20for%20dynamic%20link%20prediction) üîç | Temporal-diverse memory | 2024 |
| **TG-Mixer** | [Interactions exhibit clustering rhythm: A prevalent observation for advancing temporal link prediction,](https://scholar.google.com/scholar?q=Interactions%20exhibit%20clustering%20rhythm%3A%20A%20prevalent%20observation%20for%20advancing%20temporal%20link%20prediction%2C) üîç | Time Encoding | 2024 |
| **MLP-based Methods** | | | |
| **GraphMixer** | [Do we really need complicated model architectures for temporal networks?](http://arxiv.org/pdf/2302.11636) `[PDF]` | Fixed Time Encoding | 2024 |
| **RepeatMixer** | [Repeat-aware neighbor sampling for dynamic graph learning](https://scholar.google.com/scholar?q=Repeat-aware%20neighbor%20sampling%20for%20dynamic%20graph%20learning) üîç | Time-aware aggregation | 2024 |
| **BandRank** | [Ranking on dynamic graphs: An effective and robust band-pass disentangled approach,](https://doi.org/10.1145/3696410.3714943) `[DOI]` | Band-pass Time Filters | 2025 |

### Benchmarks
| Benchmark    | Paper                                                                                                                                              | Repository                                                                  | Specialize       | Year |
|--------------|----------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------|------------------|:----:|
| PyG-Temporal | /                                                                                                                                                  | [GitHub](https://github.com/benedekrozemberczki/pytorch_geometric_temporal) | DTDG             | 2021 |
| TGL          | [arXiv](https://arxiv.org/abs/2203.14883)                                                                                                          | [GitHub](https://github.com/amazon-science/tgl)                             | Large-scale CTDG | 2022 |
| SPEED        | [arXiv](https://arxiv.org/abs/2308.14129)                                                                                                          | [GitHub](https://github.com/chenxi1228/SPEED)                               | Large-scale CTDG | 2023 |
| DYGL         | [APWeb](https://link.springer.com/chapter/10.1007/978-981-97-2387-4_26)                                                                            | [GitHub](https://github.com/half-salve/DYGL-lib)                            | DTDG and CTDG    | 2023 |
| DyGLib       | [NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d611019afba70d547bd595e8a4158f55-Abstract-Conference.html)                    | [GitHub](https://github.com/yule-BUAA/DyGLib)                               | CTDG             | 2024 |
| TGB          | [NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2024/hash/fda026cf2423a01fcbcf1e1e43ee9a50-Abstract-Datasets_and_Benchmarks_Track.html) | [GitHub](https://github.com/shenyangHuang/TGB)                              | CTDG             | 2024 |
| BenchTemp    | [ICDE](https://www.computer.org/csdl/proceedings-article/icde/2024/1.715E49/1YOu0hGqfW8)                                                           | [GitHub](https://github.com/johnnyhuangcs/benchtemp)                        | CTDG             | 2024 |
| DGB          | [TNNLS](https://ieeexplore.ieee.org/abstract/document/10490120)                                                                                    | [GitHub](https://github.com/gravins/dynamic_graph_benchmark)                | DTDG and CTDG    | 2024 |
| BenchTGNN    | [arXiv](https://arxiv.org/abs/2412.20256)                                                                                                          | [GitHub](https://github.com/Yang-yuxin/BenchTGNN)                           | CTDG             | 2024 |
| TGX          | [WSDM](https://dl.acm.org/doi/abs/10.1145/3616855.3635694)                                                                                         | [GitHub](https://github.com/ComplexData-MILA/TGX)                           | CTDG             | 2024 |
| DGNN         | [arXiv](https://arxiv.org/abs/2405.00476)                                                                                                          | [GitHub](https://github.com/fengwudi/DGNN_model_and_data)                   | DTDG and CTDG    | 2024 |
| UTG          | [LoG](https://openreview.net/forum?id=ZKHV6Cpsxg)                                                                                                  | [GitHub](https://github.com/shenyangHuang/UTG)                              | DTDG and CTDG    | 2024 |

### Dataset Resources

[SNAP](https://snap.stanford.edu/data/index.html)

[SPEED Datasets](https://github.com/chenxi1228/SPEED)

[TGB Datasets](https://tgb.complexdatalab.com/docs/dataset_overview/)

[DyGLib Datasets](https://zenodo.org/records/7213796#.Y1cO6y8r30o)

| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **DTDG** | [DTDG](#) `[None]` | 1,744,561 | Days |
| **BSI-SVT** | [BSI-SVT](#) `[None]` | 190,133 | Weeks |
| **Bitcoin-OTC** | [Bitcoin-OTC](#) `[None]` | 35,592 | Weeks |
| **Bitcoin-Alpha** | [Bitcoin-Alpha](#) `[None]` | 24,186 | Weeks |
| **Reddit-Title** | [Reddit-Title](#) `[None]` | 571,927 | Weeks |
| **Reddit-Body** | [Reddit-Body](#) `[None]` | 286,561 | Weeks |
| **AS-733** | [AS-733](#) `[None]` | 11,965,533 | Days |
| **UCI-Message** | [UCI-Message](#) `[None]` | 59,835 | Weeks |
| **Flights** | [Flights](#) `[None]` | 1,927,145 | Days |
| **Can. Parl.** | [Can. Parl.](#) `[None]` | 74,478 | Years |
| **US Legis.** | [US Legis.](#) `[None]` | 60,396 | Congresses |
| **UN Trade** | [UN Trade](#) `[None]` | 507,497 | Years |
| **UN Vote** | [UN Vote](#) `[None]` | 1,035,742 | Years |
| **Contact** | [Contact](#) `[None]` | 2,426,279 | 5 Minutes |
| **CTDG** | [CTDG](#) `[None]` | 9,227 | Unix timestamps |
| **Reddit** | [Reddit](#) `[None]` | 672,447 | Unix timestamps |
| **MOOC** | [MOOC](#) `[None]` | 411,749 | Unix timestamps |
| **LastFM** | [LastFM](#) `[None]` | 1,293,103 | Unix timestamps |
| **Enron** | [Enron](#) `[None]` | 125,235 | Unix timestamps |
| **Social Evo.** | [Social Evo.](#) `[None]` | 2,099,519 | Unix timestamps |
| **ML25M** | [ML25M](#) `[None]` | 25,000,095 | Unix timestamps |
| **DGraphFin** | [DGraphFin](#) `[None]` | 4,300,999 | Unix timestamps |
| **Taobao** | [Taobao](#) `[None]` | 100,135,088 | Unix timestamps |
| **tgbl-review-v2** | [tgbl-review-v2](#) `[None]` | 4,873,540 | Unix timestamps |
| **tgbl-coin** | [tgbl-coin](#) `[None]` | 22,809,486 | Unix timestamps |
| **tgbl-comment** | [tgbl-comment](#) `[None]` | 44,314,507 | Unix timestamps |
| **tgbl-flight** | [tgbl-flight](#) `[None]` | 67,169,570 | Unix timestamps |



## Textual Data
### Papers
| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **LLMs for Augmenting** | | | |
| **Carranza et al.** | [Privacy-preserving recommender systems with synthetic query generation using differentially private large language models](http://arxiv.org/pdf/2305.05973) `[PDF]` | Language | 2023 |
| **TF-DCon** | [Leveraging large language models (llms) to empower training-free dataset condensation for content-based recommendation](https://scholar.google.com/scholar?q=Leveraging%20large%20language%20models%20%28llms%29%20to%20empower%20training-free%20dataset%20condensation%20for%20content-based%20recommendation) üîç | Language | 2023 |
| **CUP** | [Recommendations by concise user profiles from review text,](https://arxiv.org/abs/2311.01314) `[ArXiv]` | Language | 2023 |
| **Precious2GPT** | [Precious2gpt: the combination of multicomics pretrained transformer and conditional diffusion for artificial multi-omics multi-species multi-tissue sample generation](https://scholar.google.com/scholar?q=Precious2gpt%3A%20the%20combination%20of%20multicomics%20pretrained%20transformer%20and%20conditional%20diffusion%20for%20artificial%20multi-omics%20multi-species%20multi-tissue%20sample%20generation) üîç | Multi-omics ‚Üí Language | 2024 |
| **TriSum** | [Trisum: Learning summarization ability from large language models with structured rationale](https://arxiv.org/abs/2403.10351) `[ArXiv]` | Sequence ‚Üí Language | 2024 |
| **Chen et al.** | [Beyond numbers: Creating analogies to enhance data comprehension and communication with generative ai](https://scholar.google.com/scholar?q=Beyond%20numbers%3A%20Creating%20analogies%20to%20enhance%20data%20comprehension%20and%20communication%20with%20generative%20ai) üîç | Sequence ‚Üí Language | 2024 |
| **KAR** | [Towards open-world recommendation with knowledge augmentation from large language models,](https://dl.acm.org/doi/pdf/10.1145/3640457.3688104) `[PDF]` | Language | 2024 |
| **Ghanem et al.** | [Fine-tuning vs. prompting: evaluating the knowledge graph construction with llms,](https://scholar.google.com/scholar?q=Fine-tuning%20vs.%20prompting%3A%20evaluating%20the%20knowledge%20graph%20construction%20with%20llms%2C) üîç | Graph ‚Üí Language | 2024 |
| **Ghanem et al.** | [Enhancing knowledge graph construction: Evaluating with emphasis on hallucination, omission, and graph similarity metrics,](https://scholar.google.com/scholar?q=Enhancing%20knowledge%20graph%20construction%3A%20Evaluating%20with%20emphasis%20on%20hallucination%2C%20omission%2C%20and%20graph%20similarity%20metrics%2C) üîç | Graph ‚Üí Language | 2024 |
| **APLe** | [Aple: Tokenwise adaptive for multi-modal prompt learning,](https://arxiv.org/abs/2401.06827) `[ArXiv]` | Sequence (multi-modal) ‚Üí Language | 2024 |
| **KAG** | [Kag: Boosting llms in professional domains via knowledge augmented generation,](https://scholar.google.com/scholar?q=Kag%3A%20Boosting%20llms%20in%20professional%20domains%20via%20knowledge%20augmented%20generation%2C) üîç | Language | 2025 |
| **SAGCN** | [Understanding before recommendation: Semantic aspect-aware review exploitation via large language models](https://scholar.google.com/scholar?q=Understanding%20before%20recommendation%3A%20Semantic%20aspect-aware%20review%20exploitation%20via%20large%20language%20models) üîç | Sequence ‚Üí Language | 2025 |
| **Pandey et al.** | [Generating product reviews from aspect-based ratings using large language models](https://scholar.google.com/scholar?q=Generating%20product%20reviews%20from%20aspect-based%20ratings%20using%20large%20language%20models) üîç | Sequence ‚Üí Language | 2025 |
| **DyLas** | [Dylas: A dynamic label alignment strategy for large-scale multi-label text classification](https://scholar.google.com/scholar?q=Dylas%3A%20A%20dynamic%20label%20alignment%20strategy%20for%20large-scale%20multi-label%20text%20classification) üîç | Language | 2025 |
| **LLMs for Encoding** | | | |
| **U-BERT** | [U-bert: Pre-training user representations for improved recommendation,](https://scholar.google.com/scholar?q=U-bert%3A%20Pre-training%20user%20representations%20for%20improved%20recommendation%2C) üîç | Language | 2021 |
| **Social-LLM** | [Social-llm: Modeling user behavior at scale using language models and social network data](https://scholar.google.com/scholar?q=Social-llm%3A%20Modeling%20user%20behavior%20at%20scale%20using%20language%20models%20and%20social%20network%20data) üîç | Graph ‚Üí Language | 2023 |
| **Brooks et al.** | [Emotion expression estimates to measure and improve multimodal social-affective interactions](https://doi.org/10.1145/3610661.3616129) `[DOI]` | Sequence ‚Üí Language | 2023 |
| **UFIN** | [Ufin: Universal feature interaction network for multi-domain click-through rate prediction,](https://scholar.google.com/scholar?q=Ufin%3A%20Universal%20feature%20interaction%20network%20for%20multi-domain%20click-through%20rate%20prediction%2C) üîç | Sequence ‚Üí Language | 2023 |
| **Uni_CTR** | [A unified framework for multi-domain ctr prediction via large language models](https://scholar.google.com/scholar?q=A%20unified%20framework%20for%20multi-domain%20ctr%20prediction%20via%20large%20language%20models) üîç | Sequence ‚Üí Language | 2023 |
| **GNR** | [Generative news recommendation](https://scholar.google.com/scholar?q=Generative%20news%20recommendation) üîç | Language | 2024 |
| **EAGER** | [Eager: Two-stream generative recommender with behavior-semantic collaboration](https://scholar.google.com/scholar?q=Eager%3A%20Two-stream%20generative%20recommender%20with%20behavior-semantic%20collaboration) üîç | Sequence ‚Üí Language | 2024 |
| **LC-Re** | [Adapting large language models by integrating collaborative semantics for recommendation](https://scholar.google.com/scholar?q=Adapting%20large%20language%20models%20by%20integrating%20collaborative%20semantics%20for%20recommendation) üîç | Language | 2024 |
| **OneLLM** | [Onellm: One framework to align all modalities with language](https://arxiv.org/pdf/2312.03700) `[PDF]` | Graph/Sequence ‚Üí Language | 2024 |
| **LC-Re** | [Adapting large language models by integrating collaborative semantics for recommendation](https://arxiv.org/pdf/2311.09049) `[PDF]` | Language | 2024 |
| **Lu et al.** | [A large language model-based approach for personalized search results re-ranking in professional domains,](https://ijlangstudies.org/index.php/home/article/download/v1.n2/15) `[PDF]` | Language | 2025 |
| **Chavinda et al.** | [A dual contrastive learning framework for enhanced hate speech detection in low-resource languages,](https://scholar.google.com/scholar?q=A%20dual%20contrastive%20learning%20framework%20for%20enhanced%20hate%20speech%20detection%20in%20low-resource%20languages%2C) üîç | Language | 2025 |
| **Poison-RAG** | [Poison-rag: Adversarial data poisoning attacks on retrieval-augmented generation in recommender systems,](https://scholar.google.com/scholar?q=Poison-rag%3A%20Adversarial%20data%20poisoning%20attacks%20on%20retrieval-augmented%20generation%20in%20recommender%20systems%2C) üîç | Sequence ‚Üí Language | 2025 |
| **RUNSRec** | [Enhanced universal sequence representation learning for recommender systems,](https://scholar.google.com/scholar?q=Enhanced%20universal%20sequence%20representation%20learning%20for%20recommender%20systems%2C) üîç | Sequence ‚Üí Language | 2025 |
| **Socialmind** | [Socialmind: LIm-based proactive ar social assistive system with human-like perception for in-situ live interactions](https://scholar.google.com/scholar?q=Socialmind%3A%20LIm-based%20proactive%20ar%20social%20assistive%20system%20with%20human-like%20perception%20for%20in-situ%20live%20interactions) üîç | Graph/Sequence ‚Üí Language | 2025 |
| **CROSS** | [Unifying text semantics and graph structures for temporal text-attributed graphs with large language models](https://scholar.google.com/scholar?q=Unifying%20text%20semantics%20and%20graph%20structures%20for%20temporal%20text-attributed%20graphs%20with%20large%20language%20models) üîç | Graph ‚Üí Language | 2025 |
| **Lin et al.** | [Large language models make sample-efficient recommender systems](https://scholar.google.com/scholar?q=Large%20language%20models%20make%20sample-efficient%20recommender%20systems) üîç | Sequence ‚Üí Language | 2025 |
| **LLMs for Controlling** | | | |
| **RecLLM** | [Leveraging large language models in conversational recommender systems](https://arxiv.org/abs/2305.07961) `[ArXiv]` | Language | 2023 |
| **RecMind** | [Recmind: Large language model powered agent for recommendation](https://scholar.google.com/scholar?q=Recmind%3A%20Large%20language%20model%20powered%20agent%20for%20recommendation) üîç | Language | 2023 |
| **FinCon** | [Fincon: A synthesized llm multi-agent system with conceptual verbal reinforcement for enhanced financial decision making](https://scholar.google.com/scholar?q=Fincon%3A%20A%20synthesized%20llm%20multi-agent%20system%20with%20conceptual%20verbal%20reinforcement%20for%20enhanced%20financial%20decision%20making) üîç | Language | 2024 |
| **FinAgent** | [A multimodal foundation agent for financial trading: Tool-augmented, diversified, and generalist,](https://arxiv.org/pdf/2402.18485) `[PDF]` | Language | 2024 |
| **TradingAgents** | [Tradingagents: Multiagents llm financial trading framework](https://scholar.google.com/scholar?q=Tradingagents%3A%20Multiagents%20llm%20financial%20trading%20framework) üîç | Language | 2025 |
| **TS-Reasoner** | [Domain-oriented time series inference agents for reasoning and automated analysis](https://scholar.google.com/scholar?q=Domain-oriented%20time%20series%20inference%20agents%20for%20reasoning%20and%20automated%20analysis) üîç | Language | 2025 |
| **RiskLabs** | [Risklabs: Predicting financial risk using large language model based on multimodal and multi-sources data](https://scholar.google.com/scholar?q=Risklabs%3A%20Predicting%20financial%20risk%20using%20large%20language%20model%20based%20on%20multimodal%20and%20multi-sources%20data) üîç | Language | 2025 |
| **AgentSociety** | [Agentsociety: Large-scale simulation of llm-driven generative agents advances understanding of human behaviors and society](https://scholar.google.com/scholar?q=Agentsociety%3A%20Large-scale%20simulation%20of%20llm-driven%20generative%20agents%20advances%20understanding%20of%20human%20behaviors%20and%20society) üîç | Language | 2025 |
| **ProSim** | [Simulating prosocial behavior and social contagion in llm agents under institutional interventions](https://scholar.google.com/scholar?q=Simulating%20prosocial%20behavior%20and%20social%20contagion%20in%20llm%20agents%20under%20institutional%20interventions) üîç | Language | 2025 |

### Benchmarks

| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **PyG-Temporal** | [PyG-Temporal](#) `[None]` | https://github.com/benedekrozemberczki/pytorchb√©ometric_temporal | 2021 |
| **TGL** | [TGL](#) `[None]` | https://github.com/amazon-science/tgl | 2022 |
| **SPEED** | [SPEED](#) `[None]` | https://github.com/chenxi1228/SPEED | 2023 |
| **DYGL** | [DYGL](#) `[None]` | https://github.com/half-salve/DYGL-lib | 2023 |
| **DyGLib** | [DyGLib](#) `[None]` | https://github.com/yule-BUAA/DyGLib | 2024 |
| **TGB** | [TGB](#) `[None]` | https://github.com/shenyangHuang/TGB | 2024 |
| **BenchTemp** | [BenchTemp](#) `[None]` | https://github.com/johnnyhuangcs/benchtemp | 2024 |
| **DGB** | [DGB](#) `[None]` | https://github.com/gravins/dynamic_graph_benchmark | 2024 |
| **BenchTGNN** | [BenchTGNN](#) `[None]` | https://github.com/Yang-yuxin/BenchTGNN | 2024 |
| **TGX** | [TGX](#) `[None]` | https://github.com/ComplexData-MILA/TGX | 2024 |
| **DGNN** | [DGNN](#) `[None]` | https://github.com/fengwudi/DGNN_model_and_data | 2024 |
| **UTG** | [UTG](#) `[None]` | https://github.com/shenyangHuang/UTG | 2024 |


### Dataset Resources

| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **Enron** | [Enron](#) `[None]` | 797,907 | E-mail |
| **GDELT** | [GDELT](#) `[None]` | 1,339,245 | Knowledge graph |
| **ICEWS1819** | [ICEWS1819](#) `[None]` | 1,100,071 | Knowledge graph |
| **Stack elec** | [Stack elec](#) `[None]` | 1,262,225 | Multi-round dialogue |
| **Stack ubuntu** | [Stack ubuntu](#) `[None]` | 1,497,006 | Multi-round dialogue |
| **Google map_CT** | [Google map_CT](#) `[None]` | 1,380,623 | E-commerce |
| **Amazon movies** | [Amazon movies](#) `[None]` | 3,217,324 | E-commerce |
| **Yelp** | [Yelp](#) `[None]` | 6,990,189 | E-commerce |


## Others




