# Awesome-BehaviorData [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

## Tabular Data
### Papers
| Method | Paper Title | Training Paradigm | Model Architecture | Year |
|---|---|---|---|---|
| **Tree-based Methods** | | | | |
| **XGBoost** | [Xgboost: A scalable tree boosting system,](https://scholar.google.com/scholar?q=Xgboost%3A%20A%20scalable%20tree%20boosting%20system%2C) üîç | Supervised learning | Tree | 2016 |
| **LightGBM** | [Lightgbm: A highly efficient gradient boosting decision tree,](https://scholar.google.com/scholar?q=Lightgbm%3A%20A%20highly%20efficient%20gradient%20boosting%20decision%20tree%2C) üîç | Supervised learning | Tree | 2017 |
| **CatBoost** | [Catboost: unbiased boosting with categorical features,](https://scholar.google.com/scholar?q=Catboost%3A%20unbiased%20boosting%20with%20categorical%20features%2C) üîç | Supervised learning | Tree | 2018 |
| **Deep Learning-based Methods** | | | | |
| **Wide&Deep** | [Wide & deep learning for recommender systems,](https://scholar.google.com/scholar?q=Wide%20%26%20deep%20learning%20for%20recommender%20systems%2C) üîç | Supervised learning | GLM+MLP | 2016 |
| **DeepFM** | [Deepfm: a factorization-machine based neural network for ctr prediction,](https://arxiv.org/abs/1703.04247) üìÑ | Supervised learning | FM+MLP | 2017 |
| **xDeepFM** | [xdeepfm: Combining explicit and implicit feature interactions for recommender systems,](https://scholar.google.com/scholar?q=xdeepfm%3A%20Combining%20explicit%20and%20implicit%20feature%20interactions%20for%20recommender%20systems%2C) üîç | Supervised learning | FM+MLP+CIN | 2018 |
| **TabNN** | [Tabnn: A universal neural network solution for tabular data,](https://arxiv.org/abs/2308.14129) üìÑ | Supervised learning | GBDT+MLP | 2018 |
| **RLN** | [Regularization learning networks: deep learning for tabular datasets,](https://scholar.google.com/scholar?q=Regularization%20learning%20networks%3A%20deep%20learning%20for%20tabular%20datasets%2C) üîç | Supervised learning | MLP | 2018 |
| **NODE** | [Neural oblivious decision ensembles for deep learning on tabular data,](https://arxiv.org/abs/1909.06312) üìÑ | Supervised learning | NODE | 2019 |
| **SuperTML** | [Supertml: Two-dimensional word embedding for the precognition on structured tabular data,](https://scholar.google.com/scholar?q=Supertml%3A%20Two-dimensional%20word%20embedding%20for%20the%20precognition%20on%20structured%20tabular%20data%2C) üîç | Supervised learning | CNN | 2019 |
| **TabNet** | [Tabnet: Attentive interpretable tabular learning,](https://scholar.google.com/scholar?q=Tabnet%3A%20Attentive%20interpretable%20tabular%20learning%2C) üîç | Supervised + Self-Supervised Learning | TabNet | 2019 |
| **DeepGBM** | [Deepgbm: A deep learning framework distilled by gbt for online prediction tasks,](https://scholar.google.com/scholar?q=Deepgbm%3A%20A%20deep%20learning%20framework%20distilled%20by%20gbt%20for%20online%20prediction%20tasks%2C) üîç | Supervised + Online Learning | DeepGBM | 2019 |
| **NON** | [Network on network for tabular data classification in real-world applications,](https://scholar.google.com/scholar?q=Network%20on%20network%20for%20tabular%20data%20classification%20in%20real-world%20applications%2C) üîç | Supervised learning | NON | 2020 |
| **DNF-Net** | [Dnf-net: A neural architecture for tabular data,](https://arxiv.org/abs/2006.06465) üìÑ | Supervised learning | DNF-Net | 2020 |
| **VIME** | [Vime: Extending the success of self-and semi-supervised learning to tabular domain,](https://scholar.google.com/scholar?q=Vime%3A%20Extending%20the%20success%20of%20self-and%20semi-supervised%20learning%20to%20tabular%20domain%2C) üîç | Self-Supervised + Semi-Supervised Learning | VIME | 2020 |
| **TabTransformer** | [Tabransformer: Tabular data modeling using contextual embeddings,](https://arxiv.org/abs/2012.06678) üìÑ | Supervised + Semi-supervised Learning | Transformer | 2020 |
| **ARM-Net** | [Arm-net: Adaptive relation modeling network for structured data,](https://scholar.google.com/scholar?q=Arm-net%3A%20Adaptive%20relation%20modeling%20network%20for%20structured%20data%2C) üîç | Supervised learning | ARM-Net | 2021 |
| **NPT** | [Self-attention between datapoints: Going beyond individual input-output pairs in deep learning,](https://scholar.google.com/scholar?q=Self-attention%20between%20datapoints%3A%20Going%20beyond%20individual%20input-output%20pairs%20in%20deep%20learning%2C) üîç | Supervised learning | Transformer | 2021 |
| **Regularized DNNs** | [Well-tuned simple nets excel on tabular datasets,](https://scholar.google.com/scholar?q=Well-tuned%20simple%20nets%20excel%20on%20tabular%20datasets%2C) üîç | Supervised learning | MLP | 2021 |
| **Boost-GNN** | [Boost then convolve: Gradient boosting meets graph neural networks,](https://arxiv.org/abs/2101.08543) üìÑ | Supervised learning | GBDT+GNN | 2021 |
| **DNN2LR** | [Dnn2lr: Interpretation-inspired feature crossing for real-world tabular data,](https://arxiv.org/abs/2008.09775) üìÑ | Supervised learning | DNN2LR | 2021 |
| **IGTD** | [Converting tabular data into images for deep learning with convolutional neural networks,](https://scholar.google.com/scholar?q=Converting%20tabular%20data%20into%20images%20for%20deep%20learning%20with%20convolutional%20neural%20networks%2C) üîç | Supervised learning | IGTD+CNN | 2021 |
| **FT-Transformer** | [Revisiting deep learning models for tabular data,](https://scholar.google.com/scholar?q=Revisiting%20deep%20learning%20models%20for%20tabular%20data%2C) üîç | Supervised learning | Transformer | 2021 |
| **SAINT** | [Saint: Improved neural networks for tabular data via row attention and contrastive pre-training,](https://arxiv.org/abs/2106.01342) üìÑ | Supervised + Self-Supervised Learning | SAINT | 2021 |
| **SCARF** | [Scarf: Self-supervised contrastive learning using random feature corruption,](https://arxiv.org/abs/2106.15147) üìÑ | Self-Supervised Learning | MLP | 2021 |
| **GANDALF** | [Gandalf: gated adaptive network for deep automated learning of features,](https://arxiv.org/abs/2207.08548) üìÑ | Supervised learning | GFLU | 2022 |
| **TabDDPM** | [Tabddpm: Modelling tabular data with diffusion models,](https://scholar.google.com/scholar?q=Tabddpm%3A%20Modelling%20tabular%20data%20with%20diffusion%20models%2C) üîç | Unsupervised Learning | Diffusion Model | 2022 |
| **Ptab** | [Ptab: Using the pre-trained language model for modeling tabular data,](https://arxiv.org/abs/2209.08060) üìÑ | Supervised + Self-Supervised Learning | BERT | 2022 |
| **Trompt** | [Prompt: Towards a better deep neural network for tabular data,](https://arxiv.org/abs/2305.18446) üìÑ | Supervised + Prompt learning | MLP | 2023 |
| **HYTREL** | [Hytrel: Hypergraph-enhanced tabular data representation learning,](https://scholar.google.com/scholar?q=Hytrel%3A%20Hypergraph-enhanced%20tabular%20data%20representation%20learning%2C) üîç | Supervised + Self-Supervised Learning | HYTREL | 2023 |
| **ReConTab** | [Recontab: Regularized contrastive representation learning for tabular data,](https://arxiv.org/abs/2310.18541) üìÑ | Self-Supervised | Transformer | 2023 |
| **XTab** | [Xtab: Cross-table pretraining for tabular transformers,](https://arxiv.org/abs/2305.06090) üìÑ | Supervised + Self-Supervised Learning | Transformer | 2023 |
| **MambaTab** | [Mambatab: A plug-and-play model for learning tabular data,](https://scholar.google.com/scholar?q=Mambatab%3A%20A%20plug-and-play%20model%20for%20learning%20tabular%20data%2C) üîç | Supervised learning | Mamba | 2024 |
| **BiSHop** | [Bishop: Bi-directional cellular learning for tabular data with generalized sparse modern hopfield model,](https://arxiv.org/abs/2404.03830) üìÑ | Supervised learning | BiSHop | 2024 |
| **LF-transformer** | [Lf-transformer: Latent factorizer transformer for tabular learning,](https://scholar.google.com/scholar?q=Lf-transformer%3A%20Latent%20factorizer%20transformer%20for%20tabular%20learning%2C) üîç | Supervised learning | Transformer | 2024 |
| **TabR** | [Tabr: Tabular deep learning meets nearest neighbors,](https://scholar.google.com/scholar?q=Tabr%3A%20Tabular%20deep%20learning%20meets%20nearest%20neighbors%2C) üîç | Supervised learning | TabR | 2024 |
| **TP-BERTa** | [Making pre-trained language models great on tabular prediction,](https://arxiv.org/abs/2403.01841) üìÑ | Supervised + Self-Supervised Learning | BERT | 2024 |
| **CARTE** | [Carte: pretraining and transfer for tabular learning,](https://arxiv.org/abs/2402.16785) üìÑ | Supervised + Self-Supervised Learning | Transformer | 2024 |
| **SwitchTab** | [Switchtab: Switched autoencoders are effective tabular learners,](https://scholar.google.com/scholar?q=Switchtab%3A%20Switched%20autoencoders%20are%20effective%20tabular%20learners%2C) üîç | Self-Supervised Learning | Transformer | 2024 |
| **LLM-driven Methods** | | | | |
| **TAPAS** | [Tapas: Weakly supervised table parsing via pre-training,](https://arxiv.org/abs/2004.02349) üìÑ | Self-Supervised Learning | Bert | 2020 |
| **TAPEX** | [Tapex: Table pre-training via learning a neural sql executor,](https://arxiv.org/abs/2107.07653) üìÑ | Supervised + Self-Supervised Learning | Transformer | 2022 |
| **TabLLM** | [Tabllm: Few-shot classification of tabular data with large language models,](https://scholar.google.com/scholar?q=Tabllm%3A%20Few-shot%20classification%20of%20tabular%20data%20with%20large%20language%20models%2C) üîç | Supervised + Self-Supervised Learning | Transformer | 2022 |
| **cTBLS** | [ctbls: Augmenting large language models with conversational tables,](https://arxiv.org/abs/2303.12024) üìÑ | Supervised learning | Transformer | 2023 |

### Benchmarks

| Benchmark | Paper Title | Paper | Repository | Year |
|---|---|---|---|---|
| **OpenGL-CC18** | - | [449] | https://www.openml.org/search?type=benchmark&sort=tasks INCLUDED&study_type=task&id=99 | 2017 |
| **WellTunedSimpleNets** | - | [450] | https://github.com/machinelearningnuremberg/WellTunedSimpleNets | 2021 |
| **TabularBench** | - | [77] | https://github.com/LeoGrin/tabular-benchmark | 2022 |
| **TabZilla** | - | [451] | https://github.com/naszilla/tabzilla | 2023 |
| **OpenTabs** | - | [452] | https://github.com/Chao-Ye/CM2 | 2024 |
| **TALENT** | - | [453] | https://github.com/LAMDA-Tabular/TALENT | 2024 |

### Dataset Resources


| Dataset | Paper Title | # Numeric | # Categories | # Samples | # Tasks |
|---|---|---|---|---|---|
| **California Housing (CA)** | - | 8 | 0 | 20,640 | Regression |
| **Adult (AD)** | - | 6 | 8 | 48,842 | Classification |
| **Helena (HE)** | - | 27 | 0 | 65,196 | Classification |
| **Jannis (JA)** | - | 54 | 0 | 83,733 | Classification |
| **Higgs (HI)** | - | 28 | 0 | 1,000,000 | Classification |
| **ALOI(AL)** | - | 128 | 0 | 108,000 | Classification |
| **Epsilon (EP)** | - | 2,000 | 0 | 500,000 | Classification |
| **Year (YE)** | - | 90 | 0 | 515,345 | Regression |
| **Covertype(CO)** | - | 54 | 0 | 518,012 | classification |
| **Bank(BK)** | - | 7 | 9 | 45,211 | classification |
| **Blastchar (BC)** | - | 3 | 17 | 7,043 | classification |
| **Shoppers (SH)** | - | 4 | 14 | 12,330 | classification |
| **Volkert (VO)** | - | 180 | 1 | 58,310 | classification |
| **Income (IC)** | - | 6 | 8 | 32,561 | Classification |
| **Yahoo (YA)** | - | 699 | 0 | 709,877 | Regression |
| **Microsoft (MI)** | - | 136 | 0 | 1,200,192 | Regression |

## Event Sequence

### Papers
| Method | Paper Title | Training Paradigm | Model Architecture | Year |
|---|---|---|---|---|
| **Symbolic Modeling Methods** | | | | |
| **FPMC** | [Factorizing personalized markov chains for next-basket recommendation,](https://scholar.google.com/scholar?q=Factorizing%20personalized%20markov%20chains%20for%20next-basket%20recommendation%2C) üîç | Self-supervised learning | Markov Chain | 2010 |
| **PSPM** | [Effective next-items recommendation via personalized sequential pattern mining,](https://scholar.google.com/scholar?q=Effective%20next-items%20recommendation%20via%20personalized%20sequential%20pattern%20mining%2C) üîç | Self-supervised learning | Sequential Pattern Mining | 2012 |
| **PRME** | [Personalized ranking metric embedding for next new poi recommendation,](https://scholar.google.com/scholar?q=Personalized%20ranking%20metric%20embedding%20for%20next%20new%20poi%20recommendation%2C) üîç | Self-supervised learning | Markov Chain | 2015 |
| **Deep Learning-based Methods** | | | | |
| **GRU4Rec** | [Session-based recommendations with recurrent neural networks,](https://arxiv.org/abs/1511.06939) üìÑ | Supervised learning | GRU | 2015 |
| **RMTPP** | [Recurrent marked temporal point processes: Embedding event history to vector,](https://scholar.google.com/scholar?q=Recurrent%20marked%20temporal%20point%20processes%3A%20Embedding%20event%20history%20to%20vector%2C) üîç | Self-supervised learning | RNN | 2016 |
| **NHP** | [The neural hawkes process: A neurally selfmodulating multivariate point process,](https://scholar.google.com/scholar?q=The%20neural%20hawkes%20process%3A%20A%20neurally%20selfmodulating%20multivariate%20point%20process%2C) üîç | Self-supervised learning | LSTM | 2017 |
| **Event2Vec** | [Event2vec: Learning representations of events on temporal sequences,](https://scholar.google.com/scholar?q=Event2vec%3A%20Learning%20representations%20of%20events%20on%20temporal%20sequences%2C) üîç | Supervised learning | Transformer | 2017 |
| **IRGAN** | [Irgan: A minimax game for unifying generative and discriminative information retrieval models,](https://scholar.google.com/scholar?q=Irgan%3A%20A%20minimax%20game%20for%20unifying%20generative%20and%20discriminative%20information%20retrieval%20models%2C) üîç | Semi-supervised learning | GAN | 2017 |
| **HRNN** | [Personalizing session-based recommendations with hierarchical recurrent neural networks,](https://scholar.google.com/scholar?q=Personalizing%20session-based%20recommendations%20with%20hierarchical%20recurrent%20neural%20networks%2C) üîç | Supervised learning | RNN | 2017 |
| **Caser** | [Personalized top-n sequential recommendation via convolutional sequence embedding,](https://scholar.google.com/scholar?q=Personalized%20top-n%20sequential%20recommendation%20via%20convolutional%20sequence%20embedding%2C) üîç | Supervised learning | CNN | 2018 |
| **AttRec** | [Next item recommendation with self-attention,](https://arxiv.org/abs/1808.06414) üìÑ | Supervised learning | Transformer | 2018 |
| **MANN** | [Sequential recommendation with user memory networks,](https://scholar.google.com/scholar?q=Sequential%20recommendation%20with%20user%20memory%20networks%2C) üîç | Supervised learning | Memory Network | 2018 |
| **RecGAN** | [Recgan: recurrent generative adversarial networks for recommendation systems,](https://scholar.google.com/scholar?q=Recgan%3A%20recurrent%20generative%20adversarial%20networks%20for%20recommendation%20systems%2C) üîç | Semi-supervised learning | GAN+RNN | 2018 |
| **BERT4Rec** | [Bert4rec: Sequential recommendation with bidirectional encoder representations from transformer,](https://scholar.google.com/scholar?q=Bert4rec%3A%20Sequential%20recommendation%20with%20bidirectional%20encoder%20representations%20from%20transformer%2C) üîç | Self-supervised learning | BERT | 2019 |
| **DTCDR** | [Dtcdr: A framework for dual-target cross-domain recommendation,](https://scholar.google.com/scholar?q=Dtcdr%3A%20A%20framework%20for%20dual-target%20cross-domain%20recommendation%2C) üîç | Supervised learning | MLP | 2019 |
| **FDSA** | [Feature-level deeper self-attention network for sequential recommendation.](https://scholar.google.com/scholar?q=Feature-level%20deeper%20self-attention%20network%20for%20sequential%20recommendation.) üîç | Supervised learning | Transformer | 2019 |
| **NextItNet** | [A simple convolutional generative network for next item recommendation,](https://scholar.google.com/scholar?q=A%20simple%20convolutional%20generative%20network%20for%20next%20item%20recommendation%2C) üîç | Supervised learning | CNN | 2019 |
| **SAHP** | [Self-attentive hawkes process,](https://scholar.google.com/scholar?q=Self-attentive%20hawkes%20process%2C) üîç | Self-supervised learning | Transformer | 2020 |
| **THP** | [Transformer hawkes process,](https://scholar.google.com/scholar?q=Transformer%20hawkes%20process%2C) üîç | Self-supervised learning | Transformer | 2020 |
| **BEHRT** | [Behrt: transformer for electronic health records,](https://scholar.google.com/scholar?q=Behrt%3A%20transformer%20for%20electronic%20health%20records%2C) üîç | Self-supervised learning | BERT | 2020 |
| **TiSASRec** | [Time interval aware self-attention for sequential recommendation,](https://scholar.google.com/scholar?q=Time%20interval%20aware%20self-attention%20for%20sequential%20recommendation%2C) üîç | Supervised learning | Transformer | 2020 |
| **RAPT** | [Rapt: Pre-training of time-aware transformer for learning robust healthcare representation,](https://scholar.google.com/scholar?q=Rapt%3A%20Pre-training%20of%20time-aware%20transformer%20for%20learning%20robust%20healthcare%20representation%2C) üîç | Self-supervised learning | Transformer | 2021 |
| **CoSeRec** | [Contrastive self-supervised sequential recommendation with robust augmentation,](https://arxiv.org/abs/2108.06479) üìÑ | Self-supervised learning | GAN+CL | 2021 |
| **ASReP** | [Augmenting sequential recommendation with pseudo-prior items via reversely pre-training transformer,](https://scholar.google.com/scholar?q=Augmenting%20sequential%20recommendation%20with%20pseudo-prior%20items%20via%20reversely%20pre-training%20transformer%2C) üîç | Supervised learning | Transformer | 2021 |
| **UniSRec** | [Towards universal sequence representation learning for recommender systems,](https://scholar.google.com/scholar?q=Towards%20universal%20sequence%20representation%20learning%20for%20recommender%20systems%2C) üîç | Self-supervised learning | BERT+Transformer | 2022 |
| **RecGURU** | [Recguru: Adversarial learning of generalized user representations for cross-domain recommendation,](https://scholar.google.com/scholar?q=Recguru%3A%20Adversarial%20learning%20of%20generalized%20user%20representations%20for%20cross-domain%20recommendation%2C) üîç | Self-supervised learning | Transformer | 2022 |
| **promptTPP** | [Prompt-augmented temporal point process for streaming event sequence,](https://scholar.google.com/scholar?q=Prompt-augmented%20temporal%20point%20process%20for%20streaming%20event%20sequence%2C) üîç | Continual learning | Transformer+ Prompts | 2023 |
| **Meta TPP** | [Meta temporal point processes,](https://arxiv.org/abs/2301.12023) üìÑ | Meta learning | Transformer | 2023 |
| **BERT4ETH** | [Bert4eth: A pretrained transformer for ethereum fraud detection,](https://scholar.google.com/scholar?q=Bert4eth%3A%20A%20pretrained%20transformer%20for%20ethereum%20fraud%20detection%2C) üîç | Self-supervised learning | BERT | 2023 |
| **PrimeNet** | [Primenet: Pre-training for irregular multivariate time series,](https://scholar.google.com/scholar?q=Primenet%3A%20Pre-training%20for%20irregular%20multivariate%20time%20series%2C) üîç | Self-supervised learning | Transformer | 2023 |
| **ECGAN-Rec** | [Enhancing sequential recommendation with contrastive generative adversarial network,](https://scholar.google.com/scholar?q=Enhancing%20sequential%20recommendation%20with%20contrastive%20generative%20adversarial%20network%2C) üîç | Semi-supervised learning | GAN | 2023 |
| **Player2Vec** | [player2vec: A language modeling approach to understand player behavior in games,](https://arxiv.org/abs/2404.04234) üìÑ | Self-supervised learning | BERT | 2024 |
| **Residual TPP** | [Residual TPP: A unified lightweight approach for event stream data analysis,](https://scholar.google.com/scholar?q=Residual%20TPP%3A%20A%20unified%20lightweight%20approach%20for%20event%20stream%20data%20analysis%2C) üîç | Self-supervised learning | Hawkes + Neural TPP | 2025 |
| **IOCLRc** | [Intent oriented contrastive learning for sequential recommendation,](https://scholar.google.com/scholar?q=Intent%20oriented%20contrastive%20learning%20for%20sequential%20recommendation%2C) üîç | Self-supervised learning | Transformer+CL | 2025 |
| **HORAE** | [Horae: Temporal multi-interest pre-training for sequential recommendation,](https://doi.org/10.1145/3727645) üîó | Self-supervised learning | Transformer | 2025 |

### Benchmarks


| Benchmark | Paper Title | Paper | Repository | Year |
|---|---|---|---|---|
| **GRU** | - | [105] | https://github.com/clientGe/Sequential_Recommendation_Tensorflow | 2015 |
| **BERT** | - | [80] | https://github.com/google-research/bert | 2017 |
| **CPC** | - | [470] | https://github.com/davidtellz/contrastive-predictive-coding | 2018 |
| **Transformer** | - | [2] | https://github.com/jadore801120/attention-is-all-you-need-pytorch | 2017 |
| **PrimeNet** | - | [130] | https://github.com/ranakroychowdhury/PrimeNet | 2023 |
| **RMTPP** | - | [106] | https://github.com/ivan-chai/hotpp-benchmark | 2016 |



### Dataset Resources

| Dataset | Paper Title | # Users | # Items/Businesses | # Samples | # Domain |
|---|---|---|---|---|---|
| **Amazon Product Reviews 2023** | - | 54.51M | 48.19M | 571.54M | E-commerce |
| **Amazon Q&A** | - | - | 191K | 1.48M Q, 4.02M A | E-commerce |
| **ModCloth Marketing Bias** | - | 44.78K | 1.02K | 99.89K | E-commerce |
| **Google Local Reviews 2021** | - | 113.64M | 4.96M | 666.32M | Local Services |
| **Google Restaurants** | - | 1.01M | 65K | 1.77M | Local Services |
| **Twitch** | - | 15.5M | 465K | 124M | Media Content |
| **Food.com Recipe & Review** | - | 226.57K | 231.64K | 1,13M | Media Content |
| **EndoMondo Fitness Tracking Data** | - | 1.10K | - | 253.02K | Healthcare |
| **Behance Community Art Data** | - | 63.50K | 178.79K | 1M | Art |
| **Taobao UserBehavior** | - | 987.99K | 4.16M | 100.15M | E-commerce |
| **MovieLens 32M** | - | 200.95K | 87.59K | 32.00M Ratings, 2.00M Tag Applications | Media Content |
| **Steam Video Game and Bundle Data** | - | 2.57M | 15.47K Items, 615 Bundles | 7.79M | Gaming |



## Dynamic Graph

### Papers
#### Discrete-Time Dynamic Graph (DTDG)
| Method | Paper Title | Structural Encoding | Temporal Encoding | Year |
|---|---|---|---|---|
| **Static Embedding + Temporal Alignment Methods** | | | | |
| **Chakrabarti et al. , Chi et al. ,Kim & Han , Gupta et al. ,Yao et al. , Zhou et al.** | [Evolutionary clustering,](https://scholar.google.com/scholar?q=Evolutionary%20clustering%2C) üîç | Matrix factorization | Smoothness regularization or alignment | 2006-2018 |
| **Hisano** | [Semi-supervised graph embedding approach to dynamic link prediction,](https://scholar.google.com/scholar?q=Semi-supervised%20graph%20embedding%20approach%20to%20dynamic%20link%20prediction%2C) üîç | Matrix factorization | Time window aggregation | 2018 |
| **Sharan & Neville** | [Temporal-relational classifiers for prediction in evolving domains,](https://scholar.google.com/scholar?q=Temporal-relational%20classifiers%20for%20prediction%20in%20evolving%20domains%2C) üîç | Matrix factorization | Time-weighted adjacency matrices | 2008 |
| **Ibrahim et al.** | [Link prediction in dynamic social networks by integrating different types of information,](https://scholar.google.com/scholar?q=Link%20prediction%20in%20dynamic%20social%20networks%20by%20integrating%20different%20types%20of%20information%2C) üîç | Matrix factorization | Exponential decay | 2015 |
| **Ahmed et al.** | [Sampling-based algorithm for link prediction in temporal networks,](https://scholar.google.com/scholar?q=Sampling-based%20algorithm%20for%20link%20prediction%20in%20temporal%20networks%2C) üîç | Low-rank adjacency | Temporal sampling strategies | 2016 |
| **Singer et al.** | [Node embedding over temporal graphs,](https://arxiv.org/abs/1903.08889) üìÑ | Random walk | Init. from previous step + fine-tuning | 2019 |
| **DynGEM** | [Dyngem: Deep embedding method for dynamic graphs,](https://arxiv.org/abs/1805.11273) üìÑ | Deep autoencoder | Regularization across snapshots | 2018 |
| **DynamicTriad** | [Dynamic network embedding by modeling triadic closure process,](https://scholar.google.com/scholar?q=Dynamic%20network%20embedding%20by%20modeling%20triadic%20closure%20process%2C) üîç | Triadic closure | Temporal smoothness | 2018 |
| **GNN+RNN-based Methods** | | | | |
| **GCRN** | [Structured sequence modeling with graph convolutional recurrent networks,](https://scholar.google.com/scholar?q=Structured%20sequence%20modeling%20with%20graph%20convolutional%20recurrent%20networks%2C) üîç | GCN | LSTM | 2018 |
| **Narayan & Roe** | [Learning graph dynamics using deep neural networks,](https://scholar.google.com/scholar?q=Learning%20graph%20dynamics%20using%20deep%20neural%20networks%2C) üîç | GraphSAGE | LSTM | 2018 |
| **TGCN** | [T-gcn: A temporal graph convolutional network for traffic prediction,](https://scholar.google.com/scholar?q=T-gcn%3A%20A%20temporal%20graph%20convolutional%20network%20for%20traffic%20prediction%2C) üîç | GCN | GRU | 2019 |
| **TNA** | [Temporal neighbourhood aggregation: Predicting future links in temporal graphs via recurrent variational graph convolutions,](https://scholar.google.com/scholar?q=Temporal%20neighbourhood%20aggregation%3A%20Predicting%20future%20links%20in%20temporal%20graphs%20via%20recurrent%20variational%20graph%20convolutions%2C) üîç | GCN | GRU | 2019 |
| **VGRNN** | [Variational graph recurrent neural networks,](https://scholar.google.com/scholar?q=Variational%20graph%20recurrent%20neural%20networks%2C) üîç | VGAE | LSTM | 2019 |
| **LRGCN** | [Predicting path failure in time-evolving graphs,](https://scholar.google.com/scholar?q=Predicting%20path%20failure%20in%20time-evolving%20graphs%2C) üîç | R-GCN | LSTM | 2019 |
| **E-LSTM-D** | [E-lstm-d: A deep learning framework for dynamic network link prediction,](https://scholar.google.com/scholar?q=E-lstm-d%3A%20A%20deep%20learning%20framework%20for%20dynamic%20network%20link%20prediction%2C) üîç | Autoencoder | LSTM | 2019 |
| **EvolveGCN** | [Evolvegn: Evolving graph convolutional networks for dynamic graphs,](https://scholar.google.com/scholar?q=Evolvegn%3A%20Evolving%20graph%20convolutional%20networks%20for%20dynamic%20graphs%2C) üîç | GCN | GRU | 2020 |
| **dygraph2vec** | [dyngraph2vec: Capturing network dynamics using dynamic graph representation learning,](https://scholar.google.com/scholar?q=dyngraph2vec%3A%20Capturing%20network%20dynamics%20using%20dynamic%20graph%20representation%20learning%2C) üîç | graph2vec | LSTM/GRU | 2020 |
| **TeMP** | [Temp: Temporal message passing for temporal knowledge graph completion,](https://scholar.google.com/scholar?q=Temp%3A%20Temporal%20message%20passing%20for%20temporal%20knowledge%20graph%20completion%2C) üîç | GCN | GRU or Attention | 2020 |
| **WD-GCN/CD-GCN** | [Dynamic graph convolutional networks,](https://scholar.google.com/scholar?q=Dynamic%20graph%20convolutional%20networks%2C) üîç | GCN | Modified LSTM | 2020 |
| **HDGNN** | [A heterogeneous dynamical graph neural networks approach to quantify scientific impact,](https://arxiv.org/abs/2003.12042) üìÑ | Heterogeneous random walk | Bi-RNN | 2020 |
| **HTGN** | [Discretetime temporal network embedding via implicit hierarchical learning in hyperbolic space,](https://scholar.google.com/scholar?q=Discretetime%20temporal%20network%20embedding%20via%20implicit%20hierarchical%20learning%20in%20hyperbolic%20space%2C) üîç | Hyperbolic attention-based GCN | Hyperbolic GRU | 2021 |
| **GC-LSTM** | [Gc-lstm: Graph convolution embedded LSTM for dynamic network link prediction,](https://scholar.google.com/scholar?q=Gc-lstm%3A%20Graph%20convolution%20embedded%20LSTM%20for%20dynamic%20network%20link%20prediction%2C) üîç | GCN | LSTM | 2022 |
| **ROLAND** | [Roland: graph learning framework for dynamic graphs,](https://scholar.google.com/scholar?q=Roland%3A%20graph%20learning%20framework%20for%20dynamic%20graphs%2C) üîç | GCN | Adaptive RNN | 2022 |
| **RPC** | [Learn from relational correlations and periodic events for temporal knowledge graph reasoning,](https://scholar.google.com/scholar?q=Learn%20from%20relational%20correlations%20and%20periodic%20events%20for%20temporal%20knowledge%20graph%20reasoning%2C) üîç | GNN | GRU | 2023 |
| **SEIGN** | [Seign: A simple and efficient graph neural network for large dynamic graphs,](https://scholar.google.com/scholar?q=Seign%3A%20A%20simple%20and%20efficient%20graph%20neural%20network%20for%20large%20dynamic%20graphs%2C) üîç | GCN-like message passing | GRU parameter adjustments | 2023 |
| **RETIA** | [Retia: relation-entity twin-interact aggregation for temporal knowledge graph extrapolation,](https://scholar.google.com/scholar?q=Retia%3A%20relation-entity%20twin-interact%20aggregation%20for%20temporal%20knowledge%20graph%20extrapolation%2C) üîç | GCN | GRU + LSTM | 2023 |
| **MegaCRN** | [Spatio-temporal meta-graph learning for traffic forecasting,](https://scholar.google.com/scholar?q=Spatio-temporal%20meta-graph%20learning%20for%20traffic%20forecasting%2C) üîç | Meta-graph learner | Custom GRU | 2023 |
| **DEFT** | [Learnable spectral wavelets on dynamic graphs to capture global interactions,](https://scholar.google.com/scholar?q=Learnable%20spectral%20wavelets%20on%20dynamic%20graphs%20to%20capture%20global%20interactions%2C) üîç | GNN | RNN-based parameter evolution +Wavelet | 2023 |
| **STGNPP** | [Spatio-temporal graph neural point process for traffic congestion event prediction,](https://scholar.google.com/scholar?q=Spatio-temporal%20graph%20neural%20point%20process%20for%20traffic%20congestion%20event%20prediction%2C) üîç | GCN +Transformer | Continuous GRU | 2023 |
| **WinGNN** | [Wingnn: dynamic graph neural networks with random gradient aggregation window,](https://scholar.google.com/scholar?q=Wingnn%3A%20dynamic%20graph%20neural%20networks%20with%20random%20gradient%20aggregation%20window%2C) üîç | GNN | Sliding window | 2023 |
| **SpikeNet** | [Scaling up dynamic graph representation learning via spiking neural networks,](https://scholar.google.com/scholar?q=Scaling%20up%20dynamic%20graph%20representation%20learning%20via%20spiking%20neural%20networks%2C) üîç | GNN | SSN | 2023 |
| **TTGCN** | [K-truss based temporal graph convolutional network for dynamic graphs,](https://scholar.google.com/scholar?q=K-truss%20based%20temporal%20graph%20convolutional%20network%20for%20dynamic%20graphs%2C) üîç | Truss-based GCN | GRU | 2024 |
| **Attention-based Methods** | | | | |
| **DySAT** | [Dysat: Deep neural representation learning on dynamic graphs via self-attention networks,](https://scholar.google.com/scholar?q=Dysat%3A%20Deep%20neural%20representation%20learning%20on%20dynamic%20graphs%20via%20self-attention%20networks%2C) üîç | Graph attention | Graph attention | 2020 |
| **TEDIC** | [Tedic: Neural modeling of behavioral patterns in dynamic social interaction networks,](https://scholar.google.com/scholar?q=Tedic%3A%20Neural%20modeling%20of%20behavioral%20patterns%20in%20dynamic%20social%20interaction%20networks%2C) üîç | Graph diffusion | Temporal Convolutional Network | 2021 |
| **DyHATR** | [Modeling dynamic heterogeneous network for link prediction using hierarchical attention with temporal mn,](https://scholar.google.com/scholar?q=Modeling%20dynamic%20heterogeneous%20network%20for%20link%20prediction%20using%20hierarchical%20attention%20with%20temporal%20mn%2C) üîç | Hierarchical attention | Temporal attentive RNN | 2021 |
| **DREAM** | [Dream: Adaptive reinforcement learning based on attention mechanism for temporal knowledge graph reasoning,](https://scholar.google.com/scholar?q=Dream%3A%20Adaptive%20reinforcement%20learning%20based%20on%20attention%20mechanism%20for%20temporal%20knowledge%20graph%20reasoning%2C) üîç | Attention | Attention + Reinforcement learning | 2023 |
| **STGNP** | [Graph neural processes for spatio-temporal extrapolation,](https://scholar.google.com/scholar?q=Graph%20neural%20processes%20for%20spatio-temporal%20extrapolation%2C) üîç | Dilated Causal Convolution | Cross-set Graph Convolution | 2023 |
| **DTFormer** | [Dtformer: A transformer-based method for discrete-time dynamic graph representation learning,](https://scholar.google.com/scholar?q=Dtformer%3A%20A%20transformer-based%20method%20for%20discrete-time%20dynamic%20graph%20representation%20learning%2C) üîç | Transformer | Transformer | 2024 |

#### Continuous-Time Dynamic Graph (CTDG)

| Method | Paper Title | Structure Encoding | Temporal Encoding | Memory-based | Year |
|---|---|---|---|---|---|
| **RNN-based Methods** | | | | | |
| **DeepCoevolve** | [Deep coevolutionary network: Embedding user and item features for recommendation,](https://arxiv.org/abs/1609.03675) üìÑ | Implicit (via sequential interactions) | RNN | No | 2018 |
| **JODIE** | [Predicting dynamic embedding trajectory in temporal interaction networks,](https://scholar.google.com/scholar?q=Predicting%20dynamic%20embedding%20trajectory%20in%20temporal%20interaction%20networks%2C) üîç | Implicit (via sequential interactions) | RNN + Projection | No | 2020 |
| **Know-Evolve** | [Know-evolve: Deep temporal reasoning for dynamic knowledge graphs,](https://scholar.google.com/scholar?q=Know-evolve%3A%20Deep%20temporal%20reasoning%20for%20dynamic%20knowledge%20graphs%2C) üîç | Implicit (via sequential interactions) | RNN | No | 2017 |
| **RE-Net** | [Recurrent event network: Autoregressive structure inferenceover temporal knowledge graphs,](https://scholar.google.com/scholar?q=Recurrent%20event%20network%3A%20Autoregressive%20structure%20inferenceover%20temporal%20knowledge%20graphs%2C) üîç | GCN | RNN | No | 2020 |
| **HierTCN** | [Hierarchical temporal convolutional networks for dynamic recommender systems,](https://scholar.google.com/scholar?q=Hierarchical%20temporal%20convolutional%20networks%20for%20dynamic%20recommender%20systems%2C) üîç | Implicit (via sequential interactions) | GRU + TCN | No | 2019 |
| **DynGESN** | [Dynamic graph echo state networks,](https://arxiv.org/abs/2110.08565) üìÑ | Implicit (via sequential interactions) | Echo State Network | No | 2021 |
| **DyGNN** | [Streaming graph neural networks,](https://scholar.google.com/scholar?q=Streaming%20graph%20neural%20networks%2C) üîç | GNN | LSTM | No | 2020 |
| **AER-AD** | [Anonymous edge representation for inductive anomaly detection in dynamic bipartite graph,](https://scholar.google.com/scholar?q=Anonymous%20edge%20representation%20for%20inductive%20anomaly%20detection%20in%20dynamic%20bipartite%20graph%2C) üîç | Local anonymous subgraph | GRU | No | 2023 |
| **RTRGN** | [Recurrent temporal revision graph networks,](https://scholar.google.com/scholar?q=Recurrent%20temporal%20revision%20graph%20networks%2C) üîç | Implicit (via sequential interactions) | RNN | No | 2023 |
| **TGN** | [Temporal graph networks for deep learning on dynamic graphs,](https://arxiv.org/abs/2006.10637) üìÑ | Implicit (via message passing) | RNN + Memory | Yes | 2020 |
| **NAT** | [Neighborhood-aware scalable temporal network representation learning,](https://scholar.google.com/scholar?q=Neighborhood-aware%20scalable%20temporal%20network%20representation%20learning%2C) üîç | Implicit (via sequential interactions) | RNN | Yes | 2022 |
| **GDCF** | [Generic and dynamic graph representation learning for crowd flow modeling,](https://scholar.google.com/scholar?q=Generic%20and%20dynamic%20graph%20representation%20learning%20for%20crowd%20flow%20modeling%2C) üîç | Spatiotemporal GNN | RNN + Memory | Yes | 2023 |
| **CDGP** | [Dynamic heterogeneous graph attention neural architecture search,](https://scholar.google.com/scholar?q=Dynamic%20heterogeneous%20graph%20attention%20neural%20architecture%20search%2C) üîç | Community message passing | Time-aware aggregation | Yes | 2023 |
| **TIGER** | [Tiger: Temporal interaction graph embedding with restarts,](https://scholar.google.com/scholar?q=Tiger%3A%20Temporal%20interaction%20graph%20embedding%20with%20restarts%2C) üîç | Implicit (via message passing) | RNN + Dual Memory | Yes | 2023 |
| **RDGL** | [Rdgsl: Dynamic graph representation learning with structure learning,](https://scholar.google.com/scholar?q=Rdgsl%3A%20Dynamic%20graph%20representation%20learning%20with%20structure%20learning%2C) üîç | Implicit (via message passing) | RNN + Memory | Yes | 2023 |
| **PRES** | [Pres: Toward scalable memory-based dynamic graph neural networks,](https://arxiv.org/abs/2402.04284) üìÑ | Implicit (via message passing) | GMM-guided memory correction | Yes | 2024 |
| **Ada-DyGNN** | [Robust knowledge adaptation for dynamic graph neural networks,](https://scholar.google.com/scholar?q=Robust%20knowledge%20adaptation%20for%20dynamic%20graph%20neural%20networks%2C) üîç | Reinforced Neighbor Update | Time-based Policy | Yes | 2024 |
| **SEAN** | [Towards adaptive neighborhood for advancing temporal interaction graph modeling,](https://scholar.google.com/scholar?q=Towards%20adaptive%20neighborhood%20for%20advancing%20temporal%20interaction%20graph%20modeling%2C) üîç | Representative Neighbor Selector | RNN + Temporal-aware aggregation | Yes | 2024 |
| **MemMap** | [Memmap: An adaptive and latent memory structure for dynamic graph learning,](https://scholar.google.com/scholar?q=Memmap%3A%20An%20adaptive%20and%20latent%20memory%20structure%20for%20dynamic%20graph%20learning%2C) üîç | Latent memory-cell grid | Systematic memory routing | Yes | 2024 |
| **MSPipe** | [Mpipe: Efficient temporal gnn training via staleness-aware pipeline,](https://scholar.google.com/scholar?q=Mpipe%3A%20Efficient%20temporal%20gnn%20training%20via%20staleness-aware%20pipeline%2C) üîç | Implicit (via message passing) | Staleness-aware update | Yes | 2024 |
| **TPP-based Methods** | | | | | |
| **HTNE** | [Embedding temporal network via neighborhood formation,](https://scholar.google.com/scholar?q=Embedding%20temporal%20network%20via%20neighborhood%20formation%2C) üîç | Historical Neighbor Modeling | Hawkes Process | No | 2018 |
| **M2DNE** | [Temporal network embedding with micro-and macro-dynamics,](https://scholar.google.com/scholar?q=Temporal%20network%20embedding%20with%20micro-and%20macro-dynamics%2C) üîç | Micro/Macro temporal co-occurrence | Hierarchical TPP | No | 2019 |
| **GHN** | [The graph hawkes network for reasoning on temporal knowledge graphs,](https://scholar.google.com/scholar?q=The%20graph%20hawkes%20network%20for%20reasoning%20on%20temporal%20knowledge%20graphs%2C) üîç | Entity-level structure modeling | Hawkes Process | No | 2019 |
| **DyRep** | [Dyrep: Learning representations over dynamic graphs,](https://scholar.google.com/scholar?q=Dyrep%3A%20Learning%20representations%20over%20dynamic%20graphs%2C) üîç | Attentive structural encoding | Multi-scale TPP | No | 2019 |
| **LDG** | [Learning temporal attention in dynamic graphs with bilinear interactions,](https://scholar.google.com/scholar?q=Learning%20temporal%20attention%20in%20dynamic%20graphs%20with%20bilinear%20interactions%2C) üîç | Edge-quality structure adaptive | Adaptive TPP | No | 2021 |
| **TREND** | [Trend: Temporal event and node dynamics for graph representation learning,](https://scholar.google.com/scholar?q=Trend%3A%20Temporal%20event%20and%20node%20dynamics%20for%20graph%20representation%20learning%2C) üîç | Implicit (via sequential interactions) | Hawkes Process + Transfer function | No | 2022 |
| **DynShare** | [Time-interval aware share recommendation via bi-directional continuous time dynamic graphs,](https://scholar.google.com/scholar?q=Time-interval%20aware%20share%20recommendation%20via%20bi-directional%20continuous%20time%20dynamic%20graphs%2C) üîç | Implicit (via sequential interactions) | Personalized TPP | No | 2023 |
| **EasyDGL** | [Easydsl: Encode, train and interpret for continuous-time dynamic graph learning,](https://scholar.google.com/scholar?q=Easydsl%3A%20Encode%2C%20train%20and%20interpret%20for%20continuous-time%20dynamic%20graph%20learning%2C) üîç | GAT | TPP + Correlation masking | No | 2024 |
| **Random Walk-based Methods** | | | | | |
| **CTDNE** | [Dynamic network embeddings: From random walks to temporal random walks,](https://scholar.google.com/scholar?q=Dynamic%20network%20embeddings%3A%20From%20random%20walks%20to%20temporal%20random%20walks%2C) üîç | Timestamp-respecting walk | Skip-Gram over walks | No | 2018 |
| **HNIP** | [Temporal network embedding with high-order nonlinear information,](https://scholar.google.com/scholar?q=Temporal%20network%20embedding%20with%20high-order%20nonlinear%20information%2C) üîç | Temporal random walk | Time-decay in walk sequence | No | 2020 |
| **CAW** | [Inductive representation learning in temporal networks via causal anonymous walks,](https://arxiv.org/abs/2101.05974) üìÑ | Causal Anonymous Walk | Hitting-count encoding | No | 2021 |
| **NeurTWs** | [Neural temporal walks: Motif-aware representation learning on continuous-time dynamic graphs,](https://scholar.google.com/scholar?q=Neural%20temporal%20walks%3A%20Motif-aware%20representation%20learning%20on%20continuous-time%20dynamic%20graphs%2C) üîç | Motif-guided random walk + ODE | ODE over walk path | No | 2022 |
| **PINT** | [Provably expressive temporal graph networks,](https://scholar.google.com/scholar?q=Provably%20expressive%20temporal%20graph%20networks%2C) üîç | Implicit (via message passing) | Provable temporal message passing | No | 2022 |
| **TPNet** | [Improving temporal link prediction via temporal walk matrix projection,](https://scholar.google.com/scholar?q=Improving%20temporal%20link%20prediction%20via%20temporal%20walk%20matrix%20projection%2C) üîç | Time-decayed walk matrix | Temporal relative encoding | No | 2024 |
| **Attention/Time Encoding-based Methods** | | | | | |
| **TGAT** | [Inductive representation learning on temporal graphs,](https://arxiv.org/abs/2002.07962) üìÑ | Temporal self-attention | Functional Time Encoding | No | 2020 |
| **TCL** | [Tcl: Transformer-based dynamic graph modelling via contrastive learning,](https://arxiv.org/abs/2105.07944) üìÑ | Transformer | Functional Time Encoding | No | 2021 |
| **OTGNet** | [Towards open temporal graph neural networks,](https://scholar.google.com/scholar?q=Towards%20open%20temporal%20graph%20neural%20networks%2C) üîç | Open graph attention | Extended Time Encoding | No | 2023 |
| **TGRank** | [Expressive and efficient representation learning for ranking links in temporal graphs,](https://scholar.google.com/scholar?q=Expressive%20and%20efficient%20representation%20learning%20for%20ranking%20links%20in%20temporal%20graphs%2C) üîç | Temporal attention ranking | Enhanced Time Encoding | No | 2023 |
| **DHGAS** | [Community-based dynamic graph learning for popularity prediction,](https://scholar.google.com/scholar?q=Community-based%20dynamic%20graph%20learning%20for%20popularity%20prediction%2C) üîç | Heterogeneous GNN + Attention | Time Encoding | No | 2023 |
| **SimpleDyG** | [On the feasibility of simple transformer for dynamic graph modeling,](https://scholar.google.com/scholar?q=On%20the%20feasibility%20of%20simple%20transformer%20for%20dynamic%20graph%20modeling%2C) üîç | Transformer | Time and Position Encoding | No | 2024 |
| **DyGFormer** | [Towards better dynamic graph learning: New architecture and unified library,](https://scholar.google.com/scholar?q=Towards%20better%20dynamic%20graph%20learning%3A%20New%20architecture%20and%20unified%20library%2C) üîç | 1-hop Neighbour + Co-occurrence | Time and Position Encoding | No | 2024 |
| **APAN** | [Apan: Asynchronous propagation attention network for real-time temporal graph embedding,](https://scholar.google.com/scholar?q=Apan%3A%20Asynchronous%20propagation%20attention%20network%20for%20real-time%20temporal%20graph%20embedding%2C) üîç | Mailbox + Attention | Time Encoding | Yes | 2021 |
| **iLoRE** | [ilore: Dynamic graph representation with instant long-term modeling and re-occurrence preservation,](https://scholar.google.com/scholar?q=ilore%3A%20Dynamic%20graph%20representation%20with%20instant%20long-term%20modeling%20and%20re-occurrence%20preservation%2C) üîç | Re-occurrence + Identity attention | Time Encoding | Yes | 2022 |
| **TDGNN** | [Continuous-time link prediction via temporal dependent graph neural network,](https://scholar.google.com/scholar?q=Continuous-time%20link%20prediction%20via%20temporal%20dependent%20graph%20neural%20network%2C) üîç | GNN + Time-decay weighting | Exponential Decay Kernel | No | 2020 |
| **DGEL** | [Dynamic graph evolution learning for recommendation,](https://scholar.google.com/scholar?q=Dynamic%20graph%20evolution%20learning%20for%20recommendation%2C) üîç | Recent interactions | Time-aware Normalization | No | 2023 |
| **SUPA** | [Instant representation learning for recommendation over large dynamic graphs,](https://scholar.google.com/scholar?q=Instant%20representation%20learning%20for%20recommendation%20over%20large%20dynamic%20graphs%2C) üîç | Implicit (via sequential interactions) | Time modeling mechanisms | No | 2023 |
| **FreeDyG** | [Freedyg: Frequency enhanced continuous-time dynamic graph model for link prediction,](https://scholar.google.com/scholar?q=Freedyg%3A%20Frequency%20enhanced%20continuous-time%20dynamic%20graph%20model%20for%20link%20prediction%2C) üîç | Fourier-enhanced GNN | Functional Time Encoding | No | 2024 |
| **CNE-N** | [Co-neighbor encoding schema: A light-cost structure encoding method for dynamic link prediction,](https://scholar.google.com/scholar?q=Co-neighbor%20encoding%20schema%3A%20A%20light-cost%20structure%20encoding%20method%20for%20dynamic%20link%20prediction%2C) üîç | Hash table-based memory | Temporal-diverse memory | Yes | 2024 |
| **TG-Mixer** | [Interactions exhibit clustering rhythm: A prevalent observation for advancing temporal link prediction,](https://arxiv.org/abs/2308.14129) üìÑ | Clustering Patterns | Time Encoding | No | 2024 |
| **MLP-based Methods** | | | | | |
| **GraphMixer** | [Do we really need complicated model architectures for temporal networks?](https://scholar.google.com/scholar?q=Do%20we%20really%20need%20complicated%20model%20architectures%20for%20temporal%20networks%3F) üîç | MLP + Mean pooling | Fixed Time Encoding | No | 2024 |
| **RepeatMixer** | [Repeat-aware neighbor sampling for dynamic graph learning,](https://scholar.google.com/scholar?q=Repeat-aware%20neighbor%20sampling%20for%20dynamic%20graph%20learning%2C) üîç | MLP + Repeat-aware sampling | Time-aware aggregation | No | 2024 |
| **BandRank** | [Ranking on dynamic graphs: An effective and robust band-pass disentangled approach,](https://scholar.google.com/scholar?q=Ranking%20on%20dynamic%20graphs%3A%20An%20effective%20and%20robust%20band-pass%20disentangled%20approach%2C) üîç | Frequency-band MLP | Band-pass Time Filters | No | 2025 |

### Benchmarks
| Benchmark    | Paper                                                                                                                                              | Repository                                                                  | Specialize       | Year |
|--------------|----------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------|------------------|:----:|
| PyG-Temporal | /                                                                                                                                                  | [GitHub](https://github.com/benedekrozemberczki/pytorch_geometric_temporal) | DTDG             | 2021 |
| TGL          | [arXiv](https://arxiv.org/abs/2203.14883)                                                                                                          | [GitHub](https://github.com/amazon-science/tgl)                             | Large-scale CTDG | 2022 |
| SPEED        | [arXiv](https://arxiv.org/abs/2308.14129)                                                                                                          | [GitHub](https://github.com/chenxi1228/SPEED)                               | Large-scale CTDG | 2023 |
| DYGL         | [APWeb](https://link.springer.com/chapter/10.1007/978-981-97-2387-4_26)                                                                            | [GitHub](https://github.com/half-salve/DYGL-lib)                            | DTDG and CTDG    | 2023 |
| DyGLib       | [NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d611019afba70d547bd595e8a4158f55-Abstract-Conference.html)                    | [GitHub](https://github.com/yule-BUAA/DyGLib)                               | CTDG             | 2024 |
| TGB          | [NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2024/hash/fda026cf2423a01fcbcf1e1e43ee9a50-Abstract-Datasets_and_Benchmarks_Track.html) | [GitHub](https://github.com/shenyangHuang/TGB)                              | CTDG             | 2024 |
| BenchTemp    | [ICDE](https://www.computer.org/csdl/proceedings-article/icde/2024/1.715E49/1YOu0hGqfW8)                                                           | [GitHub](https://github.com/johnnyhuangcs/benchtemp)                        | CTDG             | 2024 |
| DGB          | [TNNLS](https://ieeexplore.ieee.org/abstract/document/10490120)                                                                                    | [GitHub](https://github.com/gravins/dynamic_graph_benchmark)                | DTDG and CTDG    | 2024 |
| BenchTGNN    | [arXiv](https://arxiv.org/abs/2412.20256)                                                                                                          | [GitHub](https://github.com/Yang-yuxin/BenchTGNN)                           | CTDG             | 2024 |
| TGX          | [WSDM](https://dl.acm.org/doi/abs/10.1145/3616855.3635694)                                                                                         | [GitHub](https://github.com/ComplexData-MILA/TGX)                           | CTDG             | 2024 |
| DGNN         | [arXiv](https://arxiv.org/abs/2405.00476)                                                                                                          | [GitHub](https://github.com/fengwudi/DGNN_model_and_data)                   | DTDG and CTDG    | 2024 |
| UTG          | [LoG](https://openreview.net/forum?id=ZKHV6Cpsxg)                                                                                                  | [GitHub](https://github.com/shenyangHuang/UTG)                              | DTDG and CTDG    | 2024 |

### Dataset Resources

[SNAP](https://snap.stanford.edu/data/index.html)

[SPEED Datasets](https://github.com/chenxi1228/SPEED)

[TGB Datasets](https://tgb.complexdatalab.com/docs/dataset_overview/)

[DyGLib Datasets](https://zenodo.org/records/7213796#.Y1cO6y8r30o)

| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **DTDG** | [DTDG](#) `[None]` | 1,744,561 | Days |
| **BSI-SVT** | [BSI-SVT](#) `[None]` | 190,133 | Weeks |
| **Bitcoin-OTC** | [Bitcoin-OTC](#) `[None]` | 35,592 | Weeks |
| **Bitcoin-Alpha** | [Bitcoin-Alpha](#) `[None]` | 24,186 | Weeks |
| **Reddit-Title** | [Reddit-Title](#) `[None]` | 571,927 | Weeks |
| **Reddit-Body** | [Reddit-Body](#) `[None]` | 286,561 | Weeks |
| **AS-733** | [AS-733](#) `[None]` | 11,965,533 | Days |
| **UCI-Message** | [UCI-Message](#) `[None]` | 59,835 | Weeks |
| **Flights** | [Flights](#) `[None]` | 1,927,145 | Days |
| **Can. Parl.** | [Can. Parl.](#) `[None]` | 74,478 | Years |
| **US Legis.** | [US Legis.](#) `[None]` | 60,396 | Congresses |
| **UN Trade** | [UN Trade](#) `[None]` | 507,497 | Years |
| **UN Vote** | [UN Vote](#) `[None]` | 1,035,742 | Years |
| **Contact** | [Contact](#) `[None]` | 2,426,279 | 5 Minutes |
| **CTDG** | [CTDG](#) `[None]` | 9,227 | Unix timestamps |
| **Reddit** | [Reddit](#) `[None]` | 672,447 | Unix timestamps |
| **MOOC** | [MOOC](#) `[None]` | 411,749 | Unix timestamps |
| **LastFM** | [LastFM](#) `[None]` | 1,293,103 | Unix timestamps |
| **Enron** | [Enron](#) `[None]` | 125,235 | Unix timestamps |
| **Social Evo.** | [Social Evo.](#) `[None]` | 2,099,519 | Unix timestamps |
| **ML25M** | [ML25M](#) `[None]` | 25,000,095 | Unix timestamps |
| **DGraphFin** | [DGraphFin](#) `[None]` | 4,300,999 | Unix timestamps |
| **Taobao** | [Taobao](#) `[None]` | 100,135,088 | Unix timestamps |
| **tgbl-review-v2** | [tgbl-review-v2](#) `[None]` | 4,873,540 | Unix timestamps |
| **tgbl-coin** | [tgbl-coin](#) `[None]` | 22,809,486 | Unix timestamps |
| **tgbl-comment** | [tgbl-comment](#) `[None]` | 44,314,507 | Unix timestamps |
| **tgbl-flight** | [tgbl-flight](#) `[None]` | 67,169,570 | Unix timestamps |



|  | Paper Title | Dataset | # Nodes | # Edges | # Snapshots / Unique Steps | Domain | Time Granularity |
|---|---|---|---|---|---|---|---|
| **DTDG** | - | BSI-ZK | 1,744,561 | 56,194,191 | 257 | Finance | Days |
| **BSI-SVT** | - | 89,564 | 190,133 | 49 | Finance | Weeks |
| **Bitcoin-OTC** | - | 5,881 | 35,592 | 279 | Finance | Weeks |
| **Bitcoin-Alpha** | - | 3,783 | 24,186 | 274 | Finance | Weeks |
| **Reddit-Title** | - | 54,075 | 571,927 | 178 | Interaction | Weeks |
| **Reddit-Body** | - | 35,776 | 286,561 | 178 | Interaction | Weeks |
| **AS-733** | - | 7,716 | 11,965,533 | 733 | Traffic | Days |
| **UCI-Message** | - | 1,899 | 59,835 | 49 | Social | Weeks |
| **Flights** | - | 13,169 | 1,927,145 | 122 | Transport | Days |
| **Can. Parl.** | - | 734 | 74,478 | 14 | Politics | Years |
| **US Legis.** | - | 225 | 60,396 | 12 | Politics | Congresses |
| **UN Trade** | - | 255 | 507,497 | 32 | Finance | Years |
| **UN Vote** | - | 201 | 1,035,742 | 72 | Politics | Years |
| **Contact** | - | 692 | 2,426,279 | 8,064 | Proximity | 5 Minutes |
| **CTDG** | - | Wikipedia | 9,227 | 157,474 | 152,757 | Social | Unix timestamps |
| **Reddit** | - | 10,984 | 672,447 | 669,065 | Social | Unix timestamps |
| **MOOC** | - | 7,144 | 411,749 | 345,600 | Interaction | Unix timestamps |
| **LastFM** | - | 1,980 | 1,293,103 | 1,283,614 | Interaction | Unix timestamps |
| **Enron** | - | 184 | 125,235 | 22,632 | Social | Unix timestamps |
| **Social Evo.** | - | 74 | 2,099,519 | 565,932 | Proximity | Unix timestamps |
| **ML25M** | - | 221,588 | 25,000,095 | 20,115,267 | Interactions | Unix timestamps |
| **DGraphFin** | - | 4,889,537 | 4,300,999 | 821 | Finance | Unix timestamps |
| **Taobao** | - | 5,149,747 | 100,135,088 | 815,859 | E-commerce | Unix timestamps |
| **tgbl-review-v2** | - | 352,637 | 4,873,540 | 6,865 | E-commerce | Unix timestamps |
| **tgbl-coin** | - | 638,486 | 22,809,486 | 1,295,720 | Finance | Unix timestamps |
| **tgbl-comment** | - | 994,790 | 44,314,507 | 30,998,030 | Interaction | Unix timestamps |
| **tgbl-flight** | - | 18,143 | 67,169,570 | 1,385 | Transport | Unix timestamps |




## Textual Data
### Papers
| Methods | Paper Title | LLM Function | Modality Transformation | LLM Fine-tuning | Year |
|---|---|---|---|---|---|
| **LLMs for Augmenting** | | | | | |
| **Carranza et al.** | [Privacy-preserving recommender systems with synthetic query generation using differentially private large language models,](https://arxiv.org/abs/2305.05973) üìÑ | Behavior Augmentation | Language | No | 2023 |
| **TF-DCon** | [Leveraging large language models (llms) to empower training-free dataset condensation for content-based recommendation,](https://arxiv.org/abs/2310.09874) üìÑ | Behavior Augmentation | Language | No | 2023 |
| **CUP** | [Recommendations by concise user profiles from review text,](https://arxiv.org/abs/2311.01314) üìÑ | Feature Augmentation | Language | No | 2023 |
| **Precious2GPT** | [Precious2gpt: the combination of multicomics pretrained transformer and conditional diffusion for artificial multi-omics multi-species multi-tissue sample generation,](https://scholar.google.com/scholar?q=Precious2gpt%3A%20the%20combination%20of%20multicomics%20pretrained%20transformer%20and%20conditional%20diffusion%20for%20artificial%20multi-omics%20multi-species%20multi-tissue%20sample%20generation%2C) üîç | Behavior Augmentation | Multi-omics ‚Üí Language | Yes | 2024 |
| **TriSum** | [Trisum: Learning summarization ability from large language models with structured rationale,](https://arxiv.org/abs/2403.10351) üìÑ | Behavior Augmentation | Sequence ‚Üí Language | Yes | 2024 |
| **Chen et al.** | [Beyond numbers: Creating analogies to enhance data comprehension and communication with generative ai,](https://scholar.google.com/scholar?q=Beyond%20numbers%3A%20Creating%20analogies%20to%20enhance%20data%20comprehension%20and%20communication%20with%20generative%20ai%2C) üîç | Behavior Augmentation | Sequence ‚Üí Language | No | 2024 |
| **KAR** | [Towards open-world recommendation with knowledge augmentation from large language models,](https://scholar.google.com/scholar?q=Towards%20open-world%20recommendation%20with%20knowledge%20augmentation%20from%20large%20language%20models%2C) üîç | Feature Augmentation | Language | No | 2024 |
| **Ghanem et al.** | [Fine-tuning vs. prompting: evaluating the knowledge graph construction with llms,](https://scholar.google.com/scholar?q=Fine-tuning%20vs.%20prompting%3A%20evaluating%20the%20knowledge%20graph%20construction%20with%20llms%2C) üîç | Feature Augmentation | Graph ‚Üí Language | Yes | 2024 |
| **Ghanem et al.** | [Enhancing knowledge graph construction: Evaluating with emphasis on hallucination, omission, and graph similarity metrics,](https://scholar.google.com/scholar?q=Enhancing%20knowledge%20graph%20construction%3A%20Evaluating%20with%20emphasis%20on%20hallucination%2C%20omission%2C%20and%20graph%20similarity%20metrics%2C) üîç | Feature Augmentation | Graph ‚Üí Language | No | 2024 |
| **APLe** | [Aple: Tokenwise adaptive for multi-modal prompt learning,](https://arxiv.org/abs/2401.06827) üìÑ | Feature Augmentation | Sequence (multi-modal) ‚Üí Language | Yes | 2024 |
| **KAG** | [Kag: Boosting llms in professional domains via knowledge augmented generation,](https://scholar.google.com/scholar?q=Kag%3A%20Boosting%20llms%20in%20professional%20domains%20via%20knowledge%20augmented%20generation%2C) üîç | Behavior Augmentation | Language | Yes | 2025 |
| **SAGCN** | [Understanding before recommendation: Semantic aspect-aware review exploitation via large language models,](https://scholar.google.com/scholar?q=Understanding%20before%20recommendation%3A%20Semantic%20aspect-aware%20review%20exploitation%20via%20large%20language%20models%2C) üîç | Feature Augmentation | Sequence ‚Üí Language | No | 2025 |
| **Pandey et al.** | [Generating product reviews from aspect-based ratings using large language models,](https://scholar.google.com/scholar?q=Generating%20product%20reviews%20from%20aspect-based%20ratings%20using%20large%20language%20models%2C) üîç | Feature Augmentation | Sequence ‚Üí Language | Yes | 2025 |
| **DyLas** | [Dylas: A dynamic label alignment strategy for large-scale multi-label text classification,](https://scholar.google.com/scholar?q=Dylas%3A%20A%20dynamic%20label%20alignment%20strategy%20for%20large-scale%20multi-label%20text%20classification%2C) üîç | Feature Augmentation | Language | Yes | 2025 |
| **LLMs for Encoding** | | | | | |
| **U-BERT** | [U-bert: Pre-training user representations for improved recommendation,](https://scholar.google.com/scholar?q=U-bert%3A%20Pre-training%20user%20representations%20for%20improved%20recommendation%2C) üîç | Representation Enhancement | Language | Yes | 2021 |
| **Social-LLM** | [Social-llm: Modeling user behavior at scale using language models and social network data,](https://arxiv.org/abs/2401.00893) üìÑ | Representation Enhancement | Graph ‚Üí Language | No | 2023 |
| **Brooks et al.** | [Emotion expression estimates to measure and improve multimodal social-affective interactions,](https://scholar.google.com/scholar?q=Emotion%20expression%20estimates%20to%20measure%20and%20improve%20multimodal%20social-affective%20interactions%2C) üîç | Cross-modality Unification | Sequence ‚Üí Language | No | 2023 |
| **UFIN** | [Ufin: Universal feature interaction network for multi-domain click-through rate prediction,](https://arxiv.org/abs/2311.15493) üìÑ | Cross-modality Unification | Sequence ‚Üí Language | No | 2023 |
| **Uni_CTR** | [A unified framework for multi-domain ctr prediction via large language models,](https://scholar.google.com/scholar?q=A%20unified%20framework%20for%20multi-domain%20ctr%20prediction%20via%20large%20language%20models%2C) üîç | Cross-modality Unification | Sequence ‚Üí Language | No | 2023 |
| **GNR** | [Generative news recommendation,](https://scholar.google.com/scholar?q=Generative%20news%20recommendation%2C) üîç | Representation Enhancement | Language | Yes | 2024 |
| **EAGER** | [Eager: Two-stream generative recommender with behavior-semantic collaboration,](https://scholar.google.com/scholar?q=Eager%3A%20Two-stream%20generative%20recommender%20with%20behavior-semantic%20collaboration%2C) üîç | Representation Enhancement | Sequence ‚Üí Language | Yes | 2024 |
| **LC-Re** | [Adapting large language models by integrating collaborative semantics for recommendation,](https://scholar.google.com/scholar?q=Adapting%20large%20language%20models%20by%20integrating%20collaborative%20semantics%20for%20recommendation%2C) üîç | Representation Enhancement | Language | Yes | 2024 |
| **OneLLM** | [Onellm: One framework to align all modalities with language,](https://scholar.google.com/scholar?q=Onellm%3A%20One%20framework%20to%20align%20all%20modalities%20with%20language%2C) üîç | Cross-modality Unification | Graph/Sequence ‚Üí Language | Yes | 2024 |
| **LC-Re** | [Adapting large language models by integrating collaborative semantics for recommendation,](https://scholar.google.com/scholar?q=Adapting%20large%20language%20models%20by%20integrating%20collaborative%20semantics%20for%20recommendation%2C) üîç | Cross-modality Unification | Language | Yes | 2024 |
| **Lu et al.** | [A large language model-based approach for personalized search results re-ranking in professional domains,](https://scholar.google.com/scholar?q=A%20large%20language%20model-based%20approach%20for%20personalized%20search%20results%20re-ranking%20in%20professional%20domains%2C) üîç | Representation Enhancement | Language | Yes | 2025 |
| **Chavinda et al.** | [A dual contrastive learning framework for enhanced hate speech detection in low-resource languages,](https://scholar.google.com/scholar?q=A%20dual%20contrastive%20learning%20framework%20for%20enhanced%20hate%20speech%20detection%20in%20low-resource%20languages%2C) üîç | Representation Enhancement | Language | Yes | 2025 |
| **Poison-RAG** | [Poison-rag: Adversarial data poisoning attacks on retrieval-augmented generation in recommender systems,](https://scholar.google.com/scholar?q=Poison-rag%3A%20Adversarial%20data%20poisoning%20attacks%20on%20retrieval-augmented%20generation%20in%20recommender%20systems%2C) üîç | Representation Enhancement | Sequence ‚Üí Language | No | 2025 |
| **RUNSRec** | [Enhanced universal sequence representation learning for recommender systems,](https://scholar.google.com/scholar?q=Enhanced%20universal%20sequence%20representation%20learning%20for%20recommender%20systems%2C) üîç | Cross-modality Unification | Sequence ‚Üí Language | Yes | 2025 |
| **Socialmind** | [Socialmind: LIm-based proactive ar social assistive system with human-like perception for in-situ live interactions,](https://scholar.google.com/scholar?q=Socialmind%3A%20LIm-based%20proactive%20ar%20social%20assistive%20system%20with%20human-like%20perception%20for%20in-situ%20live%20interactions%2C) üîç | Cross-modality Unification | Graph/Sequence ‚Üí Language | No | 2025 |
| **CROSS** | [Unifying text semantics and graph structures for temporal text-attributed graphs with large language models,](https://arxiv.org/abs/2503.14411) üìÑ | Cross-modality Unification | Graph ‚Üí Language | Yes | 2025 |
| **Lin et al.** | [Large language models make sample-efficient recommender systems,](https://scholar.google.com/scholar?q=Large%20language%20models%20make%20sample-efficient%20recommender%20systems%2C) üîç | Cross-modality Unification | Sequence ‚Üí Language | No | 2025 |
| **LLMs for Controlling** | | | | | |
| **RecLLM** | [Leveraging large language models in conversational recommender systems,](https://arxiv.org/abs/2305.07961) üìÑ | Pipeline Control | Language | No | 2023 |
| **RecMind** | [Recmind: Large language model powered agent for recommendation,](https://arxiv.org/abs/2308.14296) üìÑ | Pipeline Control | Language | No | 2023 |
| **FinCon** | [Fincon: A synthesized llm multi-agent system with conceptual verbal reinforcement for enhanced financial decision making,](https://scholar.google.com/scholar?q=Fincon%3A%20A%20synthesized%20llm%20multi-agent%20system%20with%20conceptual%20verbal%20reinforcement%20for%20enhanced%20financial%20decision%20making%2C) üîç | Pipeline Control | Language | Yes | 2024 |
| **FinAgent** | [A multimodal foundation agent for financial trading: Tool-augmented, diversified, and generalist,](https://scholar.google.com/scholar?q=A%20multimodal%20foundation%20agent%20for%20financial%20trading%3A%20Tool-augmented%2C%20diversified%2C%20and%20generalist%2C) üîç | Pipeline Control | Language | Yes | 2024 |
| **TradingAgents** | [Tradingagents: Multiagents llm financial trading framework,](https://scholar.google.com/scholar?q=Tradingagents%3A%20Multiagents%20llm%20financial%20trading%20framework%2C) üîç | Pipeline Control | Language | Yes | 2025 |
| **TS-Reasoner** | [Domain-oriented time series inference agents for reasoning and automated analysis,](https://scholar.google.com/scholar?q=Domain-oriented%20time%20series%20inference%20agents%20for%20reasoning%20and%20automated%20analysis%2C) üîç | Pipeline Control | Language | Yes | 2025 |
| **RiskLabs** | [Risklabs: Predicting financial risk using large language model based on multimodal and multi-sources data,](https://scholar.google.com/scholar?q=Risklabs%3A%20Predicting%20financial%20risk%20using%20large%20language%20model%20based%20on%20multimodal%20and%20multi-sources%20data%2C) üîç | Pipeline Control | Language | Yes | 2025 |
| **AgentSociety** | [Agentsociety: Large-scale simulation of llm-driven generative agents advances understanding of human behaviors and society,](https://scholar.google.com/scholar?q=Agentsociety%3A%20Large-scale%20simulation%20of%20llm-driven%20generative%20agents%20advances%20understanding%20of%20human%20behaviors%20and%20society%2C) üîç | Pipeline Control | Language | Yes | 2025 |
| **ProSim** | [Simulating prosocial behavior and social contagion in llm agents under institutional interventions,](https://scholar.google.com/scholar?q=Simulating%20prosocial%20behavior%20and%20social%20contagion%20in%20llm%20agents%20under%20institutional%20interventions%2C) üîç | Pipeline Control | Language | Yes | 2025 |

### Benchmarks

| Method | Paper Title (Click for Link) | Architecture | Year |
|---|---|---|---|
| **PyG-Temporal** | [PyG-Temporal](#) `[None]` | https://github.com/benedekrozemberczki/pytorchb√©ometric_temporal | 2021 |
| **TGL** | [TGL](#) `[None]` | https://github.com/amazon-science/tgl | 2022 |
| **SPEED** | [SPEED](#) `[None]` | https://github.com/chenxi1228/SPEED | 2023 |
| **DYGL** | [DYGL](#) `[None]` | https://github.com/half-salve/DYGL-lib | 2023 |
| **DyGLib** | [DyGLib](#) `[None]` | https://github.com/yule-BUAA/DyGLib | 2024 |
| **TGB** | [TGB](#) `[None]` | https://github.com/shenyangHuang/TGB | 2024 |
| **BenchTemp** | [BenchTemp](#) `[None]` | https://github.com/johnnyhuangcs/benchtemp | 2024 |
| **DGB** | [DGB](#) `[None]` | https://github.com/gravins/dynamic_graph_benchmark | 2024 |
| **BenchTGNN** | [BenchTGNN](#) `[None]` | https://github.com/Yang-yuxin/BenchTGNN | 2024 |
| **TGX** | [TGX](#) `[None]` | https://github.com/ComplexData-MILA/TGX | 2024 |
| **DGNN** | [DGNN](#) `[None]` | https://github.com/fengwudi/DGNN_model_and_data | 2024 |
| **UTG** | [UTG](#) `[None]` | https://github.com/shenyangHuang/UTG | 2024 |


### Dataset Resources

| Datasets | Paper Title | # Entity | # Behavior | # Behavior Category | # Timestamp | Domain |
|---|---|---|---|---|---|---|
| **Enron** | - | 42,711 | 797,907 | 10 | 1,006 | E-mail |
| **GDELT** | - | 6,786 | 1,339,245 | 237 | 2,591 | Knowledge graph |
| **ICEWS1819** | - | 31,796 | 1,100,071 | 266 | 730 | Knowledge graph |
| **Stack elec** | - | 397,702 | 1,262,225 | 2 | 5,224 | Multi-round dialogue |
| **Stack ubuntu** | - | 674,248 | 1,497,006 | 2 | 4,972 | Multi-round dialogue |
| **Google map_CT** | - | 111,168 | 1,380,623 | 5 | 55,521 | E-commerce |
| **Amazon movies** | - | 293,566 | 3,217,324 | 5 | 7,287 | E-commerce |
| **Yelp** | - | 2,138,242 | 6,990,189 | 5 | 6,036 | E-commerce |


## Others




